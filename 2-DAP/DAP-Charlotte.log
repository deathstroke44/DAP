Using TensorFlow backend.
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2025-04-16 02:08:20.489332: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2025-04-16 02:08:20.493470: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000000000 Hz
2025-04-16 02:08:20.493755: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555ab10b96d0 executing computations on platform Host. Devices:
2025-04-16 02:08:20.493786: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2025-04-16 02:08:20.660068: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

******************** DAP ********************
**********  round  0
load and test: shapes for train and test, X/Y
(21102, 315)
(21102, 2)
(4385, 315)
(4385, 2)
(21102, 8, 25)
(21102, 14)
(21102, 100)
(21102,)
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
geo_code (InputLayer)           (None, 1)            0                                            
__________________________________________________________________________________________________
main_input (InputLayer)         (None, 8, 25)        0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 1, 128)       119680      geo_code[0][0]                   
__________________________________________________________________________________________________
lstm_1 (LSTM)                   (None, 8, 128)       78848       main_input[0][0]                 
__________________________________________________________________________________________________
geohash_input (InputLayer)      (None, 14)           0                                            
__________________________________________________________________________________________________
nlp_input (InputLayer)          (None, 100)          0                                            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 128)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
lstm_2 (LSTM)                   (None, 128)          131584      lstm_1[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 128)          1920        geohash_input[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 128)          12928       nlp_input[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 128)          16512       flatten_1[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 512)          0           lstm_2[0][0]                     
                                                                 dense_1[0][0]                    
                                                                 dense_2[0][0]                    
                                                                 dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 512)          262656      concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 256)          131328      dense_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 256)          1024        dense_5[0][0]                    
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 256)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 256)          0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 64)           16448       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 64)           256         dense_6[0][0]                    
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64)           0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 2)            130         activation_2[0][0]               
==================================================================================================
Total params: 773,314
Trainable params: 772,674
Non-trainable params: 640
__________________________________________________________________________________________________
None
tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn
Train on 16881 samples, validate on 4221 samples
Epoch 1/60
 - 4s - loss: 0.4355 - f1_score: 0.4128 - val_loss: 6.5628 - val_f1_score: 0.3240
Epoch 2/60
 - 2s - loss: 0.3696 - f1_score: 0.5564 - val_loss: 1.7149 - val_f1_score: 0.3720
Epoch 3/60
 - 2s - loss: 0.3616 - f1_score: 0.5737 - val_loss: 0.3191 - val_f1_score: 0.0612
Epoch 4/60
 - 2s - loss: 0.3626 - f1_score: 0.5759 - val_loss: 0.4015 - val_f1_score: 0.4901
Epoch 5/60
 - 2s - loss: 0.3568 - f1_score: 0.5769 - val_loss: 0.4754 - val_f1_score: 0.4989
Epoch 6/60
 - 2s - loss: 0.3576 - f1_score: 0.5688 - val_loss: 0.4266 - val_f1_score: 0.5031
Epoch 7/60
 - 2s - loss: 0.3551 - f1_score: 0.5701 - val_loss: 0.3392 - val_f1_score: 0.4696
Epoch 8/60
 - 2s - loss: 0.3530 - f1_score: 0.5758 - val_loss: 0.3142 - val_f1_score: 0.4419
Epoch 9/60
 - 2s - loss: 0.3536 - f1_score: 0.5798 - val_loss: 0.4236 - val_f1_score: 0.5125
Epoch 10/60
 - 2s - loss: 0.3533 - f1_score: 0.5824 - val_loss: 0.3140 - val_f1_score: 0.4086
Epoch 11/60
 - 2s - loss: 0.3517 - f1_score: 0.5870 - val_loss: 0.3332 - val_f1_score: 0.4372
Epoch 12/60
 - 2s - loss: 0.3511 - f1_score: 0.6048 - val_loss: 0.3071 - val_f1_score: 0.3625
Epoch 13/60
 - 2s - loss: 0.3493 - f1_score: 0.5779 - val_loss: 0.3624 - val_f1_score: 0.4785
Epoch 14/60
 - 2s - loss: 0.3534 - f1_score: 0.5736 - val_loss: 0.4183 - val_f1_score: 0.5014
Epoch 15/60
 - 2s - loss: 0.3500 - f1_score: 0.5867 - val_loss: 0.3607 - val_f1_score: 0.4547
Epoch 16/60
 - 2s - loss: 0.3505 - f1_score: 0.5651 - val_loss: 0.3405 - val_f1_score: 0.4736
Epoch 17/60
 - 2s - loss: 0.3479 - f1_score: 0.5832 - val_loss: 0.3954 - val_f1_score: 0.5112
Epoch 18/60
 - 2s - loss: 0.3478 - f1_score: 0.5886 - val_loss: 0.3098 - val_f1_score: 0.4317
Epoch 19/60
 - 2s - loss: 0.3494 - f1_score: 0.5937 - val_loss: 0.3171 - val_f1_score: 0.4732
Epoch 20/60
 - 2s - loss: 0.3476 - f1_score: 0.5961 - val_loss: 0.3940 - val_f1_score: 0.4894
Epoch 21/60
 - 2s - loss: 0.3486 - f1_score: 0.5907 - val_loss: 0.3384 - val_f1_score: 0.4345
Epoch 22/60
 - 2s - loss: 0.3483 - f1_score: 0.5836 - val_loss: 0.3813 - val_f1_score: 0.4758
Epoch 23/60
 - 2s - loss: 0.3476 - f1_score: 0.5995 - val_loss: 0.3160 - val_f1_score: 0.4265
Epoch 24/60
 - 2s - loss: 0.3452 - f1_score: 0.5816 - val_loss: 0.3529 - val_f1_score: 0.3553
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.934897    0.492801     0.780844     0.713849      0.840227
recall        0.775102    0.801917     0.780844     0.788509      0.780844
f1-score      0.847533    0.610458     0.780844     0.728995      0.796766
support    3446.000000  939.000000  4385.000000  4385.000000   4385.000000
auc           0.878037    0.878037     0.887113     0.878288           NaN
******************** DAP ********************
**********  round  1
load and test: shapes for train and test, X/Y
(21102, 315)
(21102, 2)
(4385, 315)
(4385, 2)
(21102, 8, 25)
(21102, 14)
(21102, 100)
(21102,)
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
geo_code (InputLayer)           (None, 1)            0                                            
__________________________________________________________________________________________________
main_input (InputLayer)         (None, 8, 25)        0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 1, 128)       119680      geo_code[0][0]                   
__________________________________________________________________________________________________
lstm_3 (LSTM)                   (None, 8, 128)       78848       main_input[0][0]                 
__________________________________________________________________________________________________
geohash_input (InputLayer)      (None, 14)           0                                            
__________________________________________________________________________________________________
nlp_input (InputLayer)          (None, 100)          0                                            
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 128)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
lstm_4 (LSTM)                   (None, 128)          131584      lstm_3[0][0]                     
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 128)          1920        geohash_input[0][0]              
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 128)          12928       nlp_input[0][0]                  
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 128)          16512       flatten_2[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 512)          0           lstm_4[0][0]                     
                                                                 dense_8[0][0]                    
                                                                 dense_9[0][0]                    
                                                                 dense_10[0][0]                   
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 512)          262656      concatenate_2[0][0]              
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 256)          131328      dense_11[0][0]                   
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 256)          1024        dense_12[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256)          0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 256)          0           activation_3[0][0]               
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 64)           16448       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 64)           256         dense_13[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64)           0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 2)            130         activation_4[0][0]               
==================================================================================================
Total params: 773,314
Trainable params: 772,674
Non-trainable params: 640
__________________________________________________________________________________________________
None
tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> fn
Train on 16881 samples, validate on 4221 samples
Epoch 1/60
 - 4s - loss: 0.4283 - f1_score: 0.4214 - val_loss: 1.9933 - val_f1_score: 0.0000e+00
Epoch 2/60
 - 2s - loss: 0.3749 - f1_score: 0.5261 - val_loss: 0.8238 - val_f1_score: 0.0000e+00
Epoch 3/60
 - 2s - loss: 0.3643 - f1_score: 0.5410 - val_loss: 0.7424 - val_f1_score: 0.0000e+00
Epoch 4/60
 - 2s - loss: 0.3604 - f1_score: 0.5716 - val_loss: 0.3302 - val_f1_score: 0.1174
Epoch 5/60
 - 2s - loss: 0.3604 - f1_score: 0.5709 - val_loss: 0.6324 - val_f1_score: 0.0000e+00
Epoch 6/60
 - 2s - loss: 0.3586 - f1_score: 0.5558 - val_loss: 0.3508 - val_f1_score: 0.0825
Epoch 7/60
 - 2s - loss: 0.3545 - f1_score: 0.5832 - val_loss: 0.3258 - val_f1_score: 0.0000e+00
Epoch 8/60
 - 2s - loss: 0.3546 - f1_score: 0.5739 - val_loss: 0.2987 - val_f1_score: 0.0120
Epoch 9/60
 - 2s - loss: 0.3524 - f1_score: 0.5846 - val_loss: 0.3035 - val_f1_score: 0.4354
Epoch 10/60
 - 2s - loss: 0.3520 - f1_score: 0.6064 - val_loss: 0.2965 - val_f1_score: 0.2497
Epoch 11/60
 - 2s - loss: 0.3527 - f1_score: 0.5946 - val_loss: 0.2951 - val_f1_score: 0.1501
Epoch 12/60
 - 2s - loss: 0.3525 - f1_score: 0.5935 - val_loss: 0.3074 - val_f1_score: 0.1729
Epoch 13/60
 - 2s - loss: 0.3503 - f1_score: 0.5852 - val_loss: 0.3044 - val_f1_score: 0.2022
Epoch 14/60
 - 2s - loss: 0.3506 - f1_score: 0.5943 - val_loss: 0.2922 - val_f1_score: 0.1334
Epoch 15/60
 - 2s - loss: 0.3491 - f1_score: 0.5690 - val_loss: 0.3073 - val_f1_score: 0.3177
Epoch 16/60
 - 2s - loss: 0.3497 - f1_score: 0.5782 - val_loss: 0.3075 - val_f1_score: 0.1442
Epoch 17/60
 - 2s - loss: 0.3473 - f1_score: 0.5867 - val_loss: 0.3244 - val_f1_score: 0.3586
Epoch 18/60
 - 2s - loss: 0.3464 - f1_score: 0.6105 - val_loss: 0.3194 - val_f1_score: 0.4685
Epoch 19/60
 - 2s - loss: 0.3491 - f1_score: 0.5997 - val_loss: 0.2922 - val_f1_score: 0.1206
Epoch 20/60
 - 2s - loss: 0.3503 - f1_score: 0.5827 - val_loss: 0.3135 - val_f1_score: 0.3950
Epoch 21/60
 - 2s - loss: 0.3496 - f1_score: 0.5913 - val_loss: 0.2975 - val_f1_score: 0.0301
Epoch 22/60
 - 2s - loss: 0.3488 - f1_score: 0.5637 - val_loss: 0.2906 - val_f1_score: 0.1717
Epoch 23/60
 - 2s - loss: 0.3469 - f1_score: 0.5845 - val_loss: 0.3152 - val_f1_score: 0.2595
Epoch 24/60
 - 2s - loss: 0.3470 - f1_score: 0.5822 - val_loss: 0.3017 - val_f1_score: 0.2108
Epoch 25/60
 - 2s - loss: 0.3446 - f1_score: 0.6090 - val_loss: 0.3063 - val_f1_score: 0.1033
Epoch 26/60
 - 2s - loss: 0.3476 - f1_score: 0.6053 - val_loss: 0.3048 - val_f1_score: 0.4196
Epoch 27/60
 - 2s - loss: 0.3454 - f1_score: 0.5976 - val_loss: 0.3055 - val_f1_score: 0.2908
Epoch 28/60
 - 2s - loss: 0.3455 - f1_score: 0.5856 - val_loss: 0.3004 - val_f1_score: 0.3336
Epoch 29/60
 - 2s - loss: 0.3457 - f1_score: 0.5983 - val_loss: 0.3150 - val_f1_score: 0.3955
Epoch 30/60
 - 2s - loss: 0.3439 - f1_score: 0.6001 - val_loss: 0.2960 - val_f1_score: 0.2810
Epoch 31/60
 - 2s - loss: 0.3426 - f1_score: 0.6031 - val_loss: 0.3057 - val_f1_score: 0.4402
Epoch 32/60
 - 2s - loss: 0.3453 - f1_score: 0.5944 - val_loss: 0.3407 - val_f1_score: 0.4676
Epoch 33/60
 - 2s - loss: 0.3442 - f1_score: 0.6051 - val_loss: 0.3124 - val_f1_score: 0.4500
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.895425    0.659353     0.848803     0.777389      0.844873
recall        0.914393    0.608094     0.848803     0.761244      0.848803
f1-score      0.904810    0.632687     0.848803     0.768748      0.846538
support    3446.000000  939.000000  4385.000000  4385.000000   4385.000000
auc           0.881983    0.881983     0.927892     0.882242           NaN
******************** DAP ********************
**********  round  2
load and test: shapes for train and test, X/Y
(21102, 315)
(21102, 2)
(4385, 315)
(4385, 2)
(21102, 8, 25)
(21102, 14)
(21102, 100)
(21102,)
Model: "model_3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
geo_code (InputLayer)           (None, 1)            0                                            
__________________________________________________________________________________________________
main_input (InputLayer)         (None, 8, 25)        0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 1, 128)       119680      geo_code[0][0]                   
__________________________________________________________________________________________________
lstm_5 (LSTM)                   (None, 8, 128)       78848       main_input[0][0]                 
__________________________________________________________________________________________________
geohash_input (InputLayer)      (None, 14)           0                                            
__________________________________________________________________________________________________
nlp_input (InputLayer)          (None, 100)          0                                            
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 128)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
lstm_6 (LSTM)                   (None, 128)          131584      lstm_5[0][0]                     
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 128)          1920        geohash_input[0][0]              
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 128)          12928       nlp_input[0][0]                  
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 128)          16512       flatten_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 512)          0           lstm_6[0][0]                     
                                                                 dense_15[0][0]                   
                                                                 dense_16[0][0]                   
                                                                 dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 512)          262656      concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 256)          131328      dense_18[0][0]                   
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 256)          1024        dense_19[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256)          0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 256)          0           activation_5[0][0]               
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 64)           16448       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 64)           256         dense_20[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64)           0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 2)            130         activation_6[0][0]               
==================================================================================================
Total params: 773,314
Trainable params: 772,674
Non-trainable params: 640
__________________________________________________________________________________________________
None
tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_12:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_13:0' shape=() dtype=int32> fn
Train on 16881 samples, validate on 4221 samples
Epoch 1/60
 - 4s - loss: 0.4260 - f1_score: 0.4008 - val_loss: 1.9156 - val_f1_score: 0.0000e+00
Epoch 2/60
 - 2s - loss: 0.3732 - f1_score: 0.5321 - val_loss: 0.4875 - val_f1_score: 0.0000e+00
Epoch 3/60
 - 2s - loss: 0.3620 - f1_score: 0.5676 - val_loss: 0.3904 - val_f1_score: 0.0000e+00
Epoch 4/60
 - 2s - loss: 0.3616 - f1_score: 0.5514 - val_loss: 0.3189 - val_f1_score: 0.3392
Epoch 5/60
 - 2s - loss: 0.3616 - f1_score: 0.5724 - val_loss: 0.3057 - val_f1_score: 0.0000e+00
Epoch 6/60
 - 2s - loss: 0.3564 - f1_score: 0.5755 - val_loss: 0.3126 - val_f1_score: 0.4775
Epoch 7/60
 - 2s - loss: 0.3560 - f1_score: 0.5767 - val_loss: 0.3170 - val_f1_score: 0.4744
Epoch 8/60
 - 2s - loss: 0.3550 - f1_score: 0.5933 - val_loss: 0.2944 - val_f1_score: 0.4407
Epoch 9/60
 - 2s - loss: 0.3544 - f1_score: 0.5898 - val_loss: 0.2911 - val_f1_score: 0.3984
Epoch 10/60
 - 2s - loss: 0.3519 - f1_score: 0.5856 - val_loss: 0.3222 - val_f1_score: 0.5025
Epoch 11/60
 - 2s - loss: 0.3505 - f1_score: 0.5916 - val_loss: 0.3445 - val_f1_score: 0.4811
Epoch 12/60
 - 2s - loss: 0.3515 - f1_score: 0.5836 - val_loss: 0.2931 - val_f1_score: 0.4345
Epoch 13/60
 - 2s - loss: 0.3492 - f1_score: 0.5844 - val_loss: 0.2946 - val_f1_score: 0.3771
Epoch 14/60
 - 2s - loss: 0.3513 - f1_score: 0.5925 - val_loss: 0.3379 - val_f1_score: 0.5096
Epoch 15/60
 - 2s - loss: 0.3520 - f1_score: 0.5761 - val_loss: 0.2903 - val_f1_score: 0.4611
Epoch 16/60
 - 2s - loss: 0.3502 - f1_score: 0.5741 - val_loss: 0.3022 - val_f1_score: 0.4717
Epoch 17/60
 - 2s - loss: 0.3484 - f1_score: 0.5737 - val_loss: 0.3453 - val_f1_score: 0.5174
Epoch 18/60
 - 2s - loss: 0.3485 - f1_score: 0.5982 - val_loss: 0.3864 - val_f1_score: 0.5104
Epoch 19/60
 - 2s - loss: 0.3489 - f1_score: 0.5881 - val_loss: 0.3008 - val_f1_score: 0.4331
Epoch 20/60
 - 2s - loss: 0.3482 - f1_score: 0.5857 - val_loss: 0.3176 - val_f1_score: 0.4855
Epoch 21/60
 - 2s - loss: 0.3465 - f1_score: 0.5750 - val_loss: 0.2964 - val_f1_score: 0.4336
Epoch 22/60
 - 2s - loss: 0.3483 - f1_score: 0.5872 - val_loss: 0.2927 - val_f1_score: 0.4260
Epoch 23/60
 - 2s - loss: 0.3479 - f1_score: 0.5814 - val_loss: 0.3016 - val_f1_score: 0.4821
Epoch 24/60
 - 2s - loss: 0.3476 - f1_score: 0.5780 - val_loss: 0.2957 - val_f1_score: 0.1755
Epoch 25/60
 - 2s - loss: 0.3471 - f1_score: 0.5830 - val_loss: 0.3574 - val_f1_score: 0.5085
Epoch 26/60
 - 2s - loss: 0.3461 - f1_score: 0.6167 - val_loss: 0.2963 - val_f1_score: 0.4452
Epoch 27/60
 - 2s - loss: 0.3459 - f1_score: 0.5839 - val_loss: 0.2937 - val_f1_score: 0.4494
Epoch 28/60
 - 2s - loss: 0.3432 - f1_score: 0.5818 - val_loss: 0.2936 - val_f1_score: 0.2001
Epoch 29/60
 - 2s - loss: 0.3476 - f1_score: 0.5850 - val_loss: 0.3086 - val_f1_score: 0.4649
Epoch 30/60
 - 2s - loss: 0.3433 - f1_score: 0.6013 - val_loss: 0.3041 - val_f1_score: 0.4595
Epoch 31/60
 - 2s - loss: 0.3438 - f1_score: 0.5949 - val_loss: 0.2935 - val_f1_score: 0.4638
Epoch 32/60
 - 2s - loss: 0.3443 - f1_score: 0.6087 - val_loss: 0.3717 - val_f1_score: 0.4939
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.921830    0.559774     0.819612     0.740802      0.844300
recall        0.841846    0.738019     0.819612     0.789932      0.819612
f1-score      0.880024    0.636656     0.819612     0.758340      0.827910
support    3446.000000  939.000000  4385.000000  4385.000000   4385.000000
auc           0.885849    0.885849     0.913964     0.886104           NaN
