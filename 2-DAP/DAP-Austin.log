Using TensorFlow backend.
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2025-04-16 02:08:20.512459: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2025-04-16 02:08:20.516474: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000000000 Hz
2025-04-16 02:08:20.516752: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5572052d56d0 executing computations on platform Host. Devices:
2025-04-16 02:08:20.516776: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2025-04-16 02:08:20.681426: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

******************** DAP ********************
**********  round  0
load and test: shapes for train and test, X/Y
(22890, 315)
(22890, 2)
(4664, 315)
(4664, 2)
(22890, 8, 25)
(22890, 14)
(22890, 100)
(22890,)
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
geo_code (InputLayer)           (None, 1)            0                                            
__________________________________________________________________________________________________
main_input (InputLayer)         (None, 8, 25)        0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 1, 128)       119680      geo_code[0][0]                   
__________________________________________________________________________________________________
lstm_1 (LSTM)                   (None, 8, 128)       78848       main_input[0][0]                 
__________________________________________________________________________________________________
geohash_input (InputLayer)      (None, 14)           0                                            
__________________________________________________________________________________________________
nlp_input (InputLayer)          (None, 100)          0                                            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 128)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
lstm_2 (LSTM)                   (None, 128)          131584      lstm_1[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 128)          1920        geohash_input[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 128)          12928       nlp_input[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 128)          16512       flatten_1[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 512)          0           lstm_2[0][0]                     
                                                                 dense_1[0][0]                    
                                                                 dense_2[0][0]                    
                                                                 dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 512)          262656      concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 256)          131328      dense_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 256)          1024        dense_5[0][0]                    
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 256)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 256)          0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 64)           16448       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 64)           256         dense_6[0][0]                    
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64)           0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 2)            130         activation_2[0][0]               
==================================================================================================
Total params: 773,314
Trainable params: 772,674
Non-trainable params: 640
__________________________________________________________________________________________________
None
tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn
Train on 18312 samples, validate on 4578 samples
Epoch 1/60
 - 4s - loss: 0.3716 - f1_score: 0.3411 - val_loss: 1.1055 - val_f1_score: 0.0000e+00
Epoch 2/60
 - 3s - loss: 0.3215 - f1_score: 0.4620 - val_loss: 0.3836 - val_f1_score: 0.0000e+00
Epoch 3/60
 - 3s - loss: 0.3143 - f1_score: 0.5156 - val_loss: 0.2389 - val_f1_score: 0.0000e+00
Epoch 4/60
 - 3s - loss: 0.3140 - f1_score: 0.5238 - val_loss: 0.2015 - val_f1_score: 0.0000e+00
Epoch 5/60
 - 3s - loss: 0.3106 - f1_score: 0.5147 - val_loss: 0.3600 - val_f1_score: 0.3907
Epoch 6/60
 - 3s - loss: 0.3087 - f1_score: 0.5223 - val_loss: 0.2274 - val_f1_score: 0.0000e+00
Epoch 7/60
 - 3s - loss: 0.3097 - f1_score: 0.5119 - val_loss: 0.5180 - val_f1_score: 0.3996
Epoch 8/60
 - 3s - loss: 0.3075 - f1_score: 0.5498 - val_loss: 0.2496 - val_f1_score: 0.3600
Epoch 9/60
 - 3s - loss: 0.3053 - f1_score: 0.5332 - val_loss: 0.2773 - val_f1_score: 0.4242
Epoch 10/60
 - 3s - loss: 0.3068 - f1_score: 0.5364 - val_loss: 0.1989 - val_f1_score: 0.0000e+00
Epoch 11/60
 - 3s - loss: 0.3060 - f1_score: 0.5230 - val_loss: 0.2587 - val_f1_score: 0.2404
Epoch 12/60
 - 3s - loss: 0.3045 - f1_score: 0.5353 - val_loss: 0.2516 - val_f1_score: 0.2029
Epoch 13/60
 - 3s - loss: 0.3068 - f1_score: 0.5307 - val_loss: 0.1943 - val_f1_score: 0.0098
Epoch 14/60
 - 3s - loss: 0.3025 - f1_score: 0.5097 - val_loss: 0.1936 - val_f1_score: 0.0200
Epoch 15/60
 - 3s - loss: 0.3033 - f1_score: 0.5336 - val_loss: 0.2324 - val_f1_score: 0.1974
Epoch 16/60
 - 3s - loss: 0.3017 - f1_score: 0.5516 - val_loss: 0.2332 - val_f1_score: 0.3262
Epoch 17/60
 - 3s - loss: 0.3016 - f1_score: 0.5459 - val_loss: 0.2273 - val_f1_score: 0.2404
Epoch 18/60
 - 3s - loss: 0.3019 - f1_score: 0.5190 - val_loss: 0.2062 - val_f1_score: 0.0198
Epoch 19/60
 - 3s - loss: 0.3009 - f1_score: 0.5523 - val_loss: 0.2636 - val_f1_score: 0.3750
Epoch 20/60
 - 3s - loss: 0.2995 - f1_score: 0.5328 - val_loss: 0.3279 - val_f1_score: 0.3877
Epoch 21/60
 - 3s - loss: 0.3010 - f1_score: 0.5185 - val_loss: 0.1971 - val_f1_score: 0.1236
Epoch 22/60
 - 3s - loss: 0.3003 - f1_score: 0.5359 - val_loss: 0.2073 - val_f1_score: 0.1000
Epoch 23/60
 - 3s - loss: 0.2982 - f1_score: 0.5363 - val_loss: 0.2276 - val_f1_score: 0.0536
Epoch 24/60
 - 3s - loss: 0.2994 - f1_score: 0.5513 - val_loss: 0.2640 - val_f1_score: 0.3463
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.934207    0.600000     0.867925     0.767104      0.876810
recall        0.904220    0.692884     0.867925     0.798552      0.867925
f1-score      0.918969    0.643105     0.867925     0.781037      0.871592
support    3863.000000  801.000000  4664.000000  4664.000000   4664.000000
auc           0.902386    0.902386     0.946781     0.902647           NaN
******************** DAP ********************
**********  round  1
load and test: shapes for train and test, X/Y
(22890, 315)
(22890, 2)
(4664, 315)
(4664, 2)
(22890, 8, 25)
(22890, 14)
(22890, 100)
(22890,)
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
geo_code (InputLayer)           (None, 1)            0                                            
__________________________________________________________________________________________________
main_input (InputLayer)         (None, 8, 25)        0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 1, 128)       119680      geo_code[0][0]                   
__________________________________________________________________________________________________
lstm_3 (LSTM)                   (None, 8, 128)       78848       main_input[0][0]                 
__________________________________________________________________________________________________
geohash_input (InputLayer)      (None, 14)           0                                            
__________________________________________________________________________________________________
nlp_input (InputLayer)          (None, 100)          0                                            
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 128)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
lstm_4 (LSTM)                   (None, 128)          131584      lstm_3[0][0]                     
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 128)          1920        geohash_input[0][0]              
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 128)          12928       nlp_input[0][0]                  
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 128)          16512       flatten_2[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 512)          0           lstm_4[0][0]                     
                                                                 dense_8[0][0]                    
                                                                 dense_9[0][0]                    
                                                                 dense_10[0][0]                   
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 512)          262656      concatenate_2[0][0]              
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 256)          131328      dense_11[0][0]                   
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 256)          1024        dense_12[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256)          0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 256)          0           activation_3[0][0]               
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 64)           16448       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 64)           256         dense_13[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64)           0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 2)            130         activation_4[0][0]               
==================================================================================================
Total params: 773,314
Trainable params: 772,674
Non-trainable params: 640
__________________________________________________________________________________________________
None
tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> fn
Train on 18312 samples, validate on 4578 samples
Epoch 1/60
 - 4s - loss: 0.3650 - f1_score: 0.3220 - val_loss: 1.5076 - val_f1_score: 0.2470
Epoch 2/60
 - 3s - loss: 0.3211 - f1_score: 0.4722 - val_loss: 0.2028 - val_f1_score: 0.0000e+00
Epoch 3/60
 - 3s - loss: 0.3133 - f1_score: 0.5118 - val_loss: 0.2162 - val_f1_score: 0.0000e+00
Epoch 4/60
 - 3s - loss: 0.3128 - f1_score: 0.5245 - val_loss: 0.2137 - val_f1_score: 0.0000e+00
Epoch 5/60
 - 3s - loss: 0.3109 - f1_score: 0.5204 - val_loss: 0.2030 - val_f1_score: 0.1952
Epoch 6/60
 - 3s - loss: 0.3087 - f1_score: 0.5410 - val_loss: 0.2543 - val_f1_score: 0.3704
Epoch 7/60
 - 3s - loss: 0.3071 - f1_score: 0.5253 - val_loss: 0.4367 - val_f1_score: 0.4039
Epoch 8/60
 - 3s - loss: 0.3088 - f1_score: 0.5226 - val_loss: 0.2048 - val_f1_score: 0.0000e+00
Epoch 9/60
 - 3s - loss: 0.3070 - f1_score: 0.5256 - val_loss: 0.2113 - val_f1_score: 0.0000e+00
Epoch 10/60
 - 3s - loss: 0.3091 - f1_score: 0.4980 - val_loss: 0.2384 - val_f1_score: 0.1388
Epoch 11/60
 - 3s - loss: 0.3066 - f1_score: 0.5253 - val_loss: 0.3776 - val_f1_score: 0.4047
Epoch 12/60
 - 3s - loss: 0.3034 - f1_score: 0.5500 - val_loss: 0.2299 - val_f1_score: 0.3551
Epoch 13/60
 - 3s - loss: 0.3041 - f1_score: 0.5501 - val_loss: 0.3162 - val_f1_score: 0.3612
Epoch 14/60
 - 3s - loss: 0.3045 - f1_score: 0.5539 - val_loss: 0.1993 - val_f1_score: 0.0000e+00
Epoch 15/60
 - 3s - loss: 0.3039 - f1_score: 0.5367 - val_loss: 0.2515 - val_f1_score: 0.2820
Epoch 16/60
 - 3s - loss: 0.3028 - f1_score: 0.5283 - val_loss: 0.2086 - val_f1_score: 0.0000e+00
Epoch 17/60
 - 3s - loss: 0.3031 - f1_score: 0.5219 - val_loss: 0.2473 - val_f1_score: 0.3387
Epoch 18/60
 - 3s - loss: 0.3004 - f1_score: 0.5112 - val_loss: 0.2131 - val_f1_score: 0.1642
Epoch 19/60
 - 3s - loss: 0.3017 - f1_score: 0.5329 - val_loss: 0.2631 - val_f1_score: 0.2247
Epoch 20/60
 - 3s - loss: 0.3029 - f1_score: 0.5445 - val_loss: 0.2168 - val_f1_score: 0.1862
Epoch 21/60
 - 3s - loss: 0.2994 - f1_score: 0.5361 - val_loss: 0.2477 - val_f1_score: 0.3887
Epoch 22/60
 - 3s - loss: 0.2999 - f1_score: 0.5252 - val_loss: 0.2161 - val_f1_score: 0.1429
Epoch 23/60
 - 3s - loss: 0.2983 - f1_score: 0.5179 - val_loss: 0.2445 - val_f1_score: 0.0052
Epoch 24/60
 - 3s - loss: 0.2999 - f1_score: 0.5356 - val_loss: 0.2269 - val_f1_score: 0.1829
Epoch 25/60
 - 3s - loss: 0.3007 - f1_score: 0.5338 - val_loss: 0.2693 - val_f1_score: 0.3203
Epoch 26/60
 - 3s - loss: 0.2999 - f1_score: 0.5537 - val_loss: 0.2781 - val_f1_score: 0.2950
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.945377    0.530026     0.843053     0.737702      0.874044
recall        0.860212    0.760300     0.843053     0.810256      0.843053
f1-score      0.900786    0.624615     0.843053     0.762701      0.853356
support    3863.000000  801.000000  4664.000000  4664.000000   4664.000000
auc           0.893242    0.893242     0.925171     0.893513           NaN
******************** DAP ********************
**********  round  2
load and test: shapes for train and test, X/Y
(22890, 315)
(22890, 2)
(4664, 315)
(4664, 2)
(22890, 8, 25)
(22890, 14)
(22890, 100)
(22890,)
Model: "model_3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
geo_code (InputLayer)           (None, 1)            0                                            
__________________________________________________________________________________________________
main_input (InputLayer)         (None, 8, 25)        0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 1, 128)       119680      geo_code[0][0]                   
__________________________________________________________________________________________________
lstm_5 (LSTM)                   (None, 8, 128)       78848       main_input[0][0]                 
__________________________________________________________________________________________________
geohash_input (InputLayer)      (None, 14)           0                                            
__________________________________________________________________________________________________
nlp_input (InputLayer)          (None, 100)          0                                            
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 128)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
lstm_6 (LSTM)                   (None, 128)          131584      lstm_5[0][0]                     
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 128)          1920        geohash_input[0][0]              
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 128)          12928       nlp_input[0][0]                  
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 128)          16512       flatten_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 512)          0           lstm_6[0][0]                     
                                                                 dense_15[0][0]                   
                                                                 dense_16[0][0]                   
                                                                 dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 512)          262656      concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 256)          131328      dense_18[0][0]                   
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 256)          1024        dense_19[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256)          0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 256)          0           activation_5[0][0]               
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 64)           16448       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 64)           256         dense_20[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64)           0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 2)            130         activation_6[0][0]               
==================================================================================================
Total params: 773,314
Trainable params: 772,674
Non-trainable params: 640
__________________________________________________________________________________________________
None
tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_12:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_13:0' shape=() dtype=int32> fn
Train on 18312 samples, validate on 4578 samples
Epoch 1/60
 - 4s - loss: 0.3641 - f1_score: 0.3781 - val_loss: 0.2668 - val_f1_score: 0.0988
Epoch 2/60
 - 3s - loss: 0.3224 - f1_score: 0.4859 - val_loss: 2.2670 - val_f1_score: 0.1994
Epoch 3/60
 - 3s - loss: 0.3141 - f1_score: 0.4765 - val_loss: 0.2361 - val_f1_score: 0.0000e+00
Epoch 4/60
 - 3s - loss: 0.3118 - f1_score: 0.5182 - val_loss: 0.4022 - val_f1_score: 0.3214
Epoch 5/60
 - 3s - loss: 0.3121 - f1_score: 0.5026 - val_loss: 0.2724 - val_f1_score: 0.2799
Epoch 6/60
 - 3s - loss: 0.3081 - f1_score: 0.5231 - val_loss: 0.9605 - val_f1_score: 0.2624
Epoch 7/60
 - 3s - loss: 0.3096 - f1_score: 0.5238 - val_loss: 0.2141 - val_f1_score: 0.0000e+00
Epoch 8/60
 - 3s - loss: 0.3053 - f1_score: 0.5226 - val_loss: 0.3076 - val_f1_score: 0.4373
Epoch 9/60
 - 3s - loss: 0.3055 - f1_score: 0.5637 - val_loss: 0.3980 - val_f1_score: 0.4302
Epoch 10/60
 - 3s - loss: 0.3067 - f1_score: 0.5473 - val_loss: 0.4025 - val_f1_score: 0.4094
Epoch 11/60
 - 3s - loss: 0.3034 - f1_score: 0.5444 - val_loss: 0.3551 - val_f1_score: 0.3248
Epoch 12/60
 - 3s - loss: 0.3049 - f1_score: 0.5195 - val_loss: 0.3022 - val_f1_score: 0.1559
Epoch 13/60
 - 3s - loss: 0.3056 - f1_score: 0.5296 - val_loss: 0.2271 - val_f1_score: 0.2835
Epoch 14/60
 - 3s - loss: 0.3027 - f1_score: 0.5270 - val_loss: 0.1951 - val_f1_score: 0.0970
Epoch 15/60
 - 3s - loss: 0.3025 - f1_score: 0.5215 - val_loss: 0.2065 - val_f1_score: 0.2109
Epoch 16/60
 - 3s - loss: 0.3011 - f1_score: 0.5234 - val_loss: 0.2887 - val_f1_score: 0.3855
Epoch 17/60
 - 3s - loss: 0.3023 - f1_score: 0.5302 - val_loss: 0.2024 - val_f1_score: 0.1316
Epoch 18/60
 - 3s - loss: 0.3009 - f1_score: 0.5408 - val_loss: 0.2801 - val_f1_score: 0.3624
Epoch 19/60
 - 3s - loss: 0.2991 - f1_score: 0.5348 - val_loss: 0.3234 - val_f1_score: 0.3475
Epoch 20/60
 - 3s - loss: 0.3011 - f1_score: 0.5265 - val_loss: 0.2957 - val_f1_score: 0.4000
Epoch 21/60
 - 3s - loss: 0.2991 - f1_score: 0.5452 - val_loss: 0.2018 - val_f1_score: 0.1117
Epoch 22/60
 - 3s - loss: 0.2992 - f1_score: 0.5256 - val_loss: 0.3184 - val_f1_score: 0.3839
Epoch 23/60
 - 3s - loss: 0.2976 - f1_score: 0.5588 - val_loss: 0.2789 - val_f1_score: 0.3834
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.952159    0.515372     0.836407     0.733765      0.877145
recall        0.844939    0.795256     0.836407     0.820098      0.836407
f1-score      0.895350    0.625430     0.836407     0.760390      0.848994
support    3863.000000  801.000000  4664.000000  4664.000000   4664.000000
auc           0.892417    0.892417     0.926750     0.892678           NaN
