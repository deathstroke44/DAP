Using TensorFlow backend.
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2025-04-16 02:08:22.927156: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2025-04-16 02:08:22.930850: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000000000 Hz
2025-04-16 02:08:22.931098: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55582fe606d0 executing computations on platform Host. Devices:
2025-04-16 02:08:22.931120: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2025-04-16 02:08:23.094318: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

******************** DAP ********************
**********  round  0
load and test: shapes for train and test, X/Y
(41184, 315)
(41184, 2)
(8437, 315)
(8437, 2)
(41184, 8, 25)
(41184, 14)
(41184, 100)
(41184,)
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
geo_code (InputLayer)           (None, 1)            0                                            
__________________________________________________________________________________________________
main_input (InputLayer)         (None, 8, 25)        0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 1, 128)       119680      geo_code[0][0]                   
__________________________________________________________________________________________________
lstm_1 (LSTM)                   (None, 8, 128)       78848       main_input[0][0]                 
__________________________________________________________________________________________________
geohash_input (InputLayer)      (None, 14)           0                                            
__________________________________________________________________________________________________
nlp_input (InputLayer)          (None, 100)          0                                            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 128)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
lstm_2 (LSTM)                   (None, 128)          131584      lstm_1[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 128)          1920        geohash_input[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 128)          12928       nlp_input[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 128)          16512       flatten_1[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 512)          0           lstm_2[0][0]                     
                                                                 dense_1[0][0]                    
                                                                 dense_2[0][0]                    
                                                                 dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 512)          262656      concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 256)          131328      dense_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 256)          1024        dense_5[0][0]                    
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 256)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 256)          0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 64)           16448       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 64)           256         dense_6[0][0]                    
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64)           0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 2)            130         activation_2[0][0]               
==================================================================================================
Total params: 773,314
Trainable params: 772,674
Non-trainable params: 640
__________________________________________________________________________________________________
None
tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn
Train on 32947 samples, validate on 8237 samples
Epoch 1/60
 - 6s - loss: 0.3068 - f1_score: 0.3051 - val_loss: 3.0043 - val_f1_score: 0.1518
Epoch 2/60
 - 5s - loss: 0.2636 - f1_score: 0.3667 - val_loss: 0.1597 - val_f1_score: 0.1431
Epoch 3/60
 - 5s - loss: 0.2564 - f1_score: 0.4572 - val_loss: 0.1835 - val_f1_score: 0.0000e+00
Epoch 4/60
 - 5s - loss: 0.2521 - f1_score: 0.4201 - val_loss: 0.1617 - val_f1_score: 0.1539
Epoch 5/60
 - 5s - loss: 0.2497 - f1_score: 0.4566 - val_loss: 0.1522 - val_f1_score: 0.0634
Epoch 6/60
 - 5s - loss: 0.2491 - f1_score: 0.4661 - val_loss: 0.1961 - val_f1_score: 0.2472
Epoch 7/60
 - 5s - loss: 0.2462 - f1_score: 0.4500 - val_loss: 0.1515 - val_f1_score: 0.1628
Epoch 8/60
 - 5s - loss: 0.2462 - f1_score: 0.4784 - val_loss: 0.1659 - val_f1_score: 0.0701
Epoch 9/60
 - 5s - loss: 0.2439 - f1_score: 0.4581 - val_loss: 0.2251 - val_f1_score: 0.2944
Epoch 10/60
 - 5s - loss: 0.2454 - f1_score: 0.4859 - val_loss: 0.1922 - val_f1_score: 0.2914
Epoch 11/60
 - 5s - loss: 0.2443 - f1_score: 0.4738 - val_loss: 0.1839 - val_f1_score: 0.1898
Epoch 12/60
 - 5s - loss: 0.2450 - f1_score: 0.4669 - val_loss: 0.2000 - val_f1_score: 0.1224
Epoch 13/60
 - 5s - loss: 0.2442 - f1_score: 0.4695 - val_loss: 0.1461 - val_f1_score: 0.0720
Epoch 14/60
 - 5s - loss: 0.2442 - f1_score: 0.4835 - val_loss: 0.1649 - val_f1_score: 0.1109
Epoch 15/60
 - 5s - loss: 0.2422 - f1_score: 0.4873 - val_loss: 0.1761 - val_f1_score: 0.2089
Epoch 16/60
 - 5s - loss: 0.2434 - f1_score: 0.4546 - val_loss: 0.1601 - val_f1_score: 0.1102
Epoch 17/60
 - 5s - loss: 0.2424 - f1_score: 0.4899 - val_loss: 0.1468 - val_f1_score: 0.0935
Epoch 18/60
 - 5s - loss: 0.2430 - f1_score: 0.4753 - val_loss: 0.1468 - val_f1_score: 0.1329
Epoch 19/60
 - 5s - loss: 0.2412 - f1_score: 0.4955 - val_loss: 0.1612 - val_f1_score: 0.0791
Epoch 20/60
 - 5s - loss: 0.2427 - f1_score: 0.4848 - val_loss: 0.1434 - val_f1_score: 0.0582
Epoch 21/60
 - 5s - loss: 0.2416 - f1_score: 0.4708 - val_loss: 0.1536 - val_f1_score: 0.1528
Epoch 22/60
 - 5s - loss: 0.2430 - f1_score: 0.4841 - val_loss: 0.1466 - val_f1_score: 0.1056
Epoch 23/60
 - 5s - loss: 0.2414 - f1_score: 0.4886 - val_loss: 0.1398 - val_f1_score: 0.0713
Epoch 24/60
 - 5s - loss: 0.2416 - f1_score: 0.4856 - val_loss: 0.1468 - val_f1_score: 0.0645
                     0            1    micro avg    macro avg  weighted avg
index                                                                      
precision     0.949003     0.500330     0.868437     0.724667      0.889921
recall        0.896669     0.682268     0.868437     0.789469      0.868437
f1-score      0.922094     0.577304     0.868437     0.749699      0.876692
support    7326.000000  1111.000000  8437.000000  8437.000000   8437.000000
auc           0.904634     0.904634     0.950806     0.904803           NaN
******************** DAP ********************
**********  round  1
load and test: shapes for train and test, X/Y
(41184, 315)
(41184, 2)
(8437, 315)
(8437, 2)
(41184, 8, 25)
(41184, 14)
(41184, 100)
(41184,)
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
geo_code (InputLayer)           (None, 1)            0                                            
__________________________________________________________________________________________________
main_input (InputLayer)         (None, 8, 25)        0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 1, 128)       119680      geo_code[0][0]                   
__________________________________________________________________________________________________
lstm_3 (LSTM)                   (None, 8, 128)       78848       main_input[0][0]                 
__________________________________________________________________________________________________
geohash_input (InputLayer)      (None, 14)           0                                            
__________________________________________________________________________________________________
nlp_input (InputLayer)          (None, 100)          0                                            
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 128)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
lstm_4 (LSTM)                   (None, 128)          131584      lstm_3[0][0]                     
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 128)          1920        geohash_input[0][0]              
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 128)          12928       nlp_input[0][0]                  
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 128)          16512       flatten_2[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 512)          0           lstm_4[0][0]                     
                                                                 dense_8[0][0]                    
                                                                 dense_9[0][0]                    
                                                                 dense_10[0][0]                   
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 512)          262656      concatenate_2[0][0]              
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 256)          131328      dense_11[0][0]                   
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 256)          1024        dense_12[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256)          0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 256)          0           activation_3[0][0]               
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 64)           16448       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 64)           256         dense_13[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64)           0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 2)            130         activation_4[0][0]               
==================================================================================================
Total params: 773,314
Trainable params: 772,674
Non-trainable params: 640
__________________________________________________________________________________________________
None
tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> fn
Train on 32947 samples, validate on 8237 samples
Epoch 1/60
 - 7s - loss: 0.3062 - f1_score: 0.2822 - val_loss: 0.2313 - val_f1_score: 0.0000e+00
Epoch 2/60
 - 5s - loss: 0.2569 - f1_score: 0.4546 - val_loss: 0.4181 - val_f1_score: 0.0000e+00
Epoch 3/60
 - 5s - loss: 0.2524 - f1_score: 0.4683 - val_loss: 0.1918 - val_f1_score: 0.1069
Epoch 4/60
 - 5s - loss: 0.2498 - f1_score: 0.4485 - val_loss: 0.1508 - val_f1_score: 0.0000e+00
Epoch 5/60
 - 5s - loss: 0.2499 - f1_score: 0.4783 - val_loss: 0.1531 - val_f1_score: 0.1457
Epoch 6/60
 - 5s - loss: 0.2483 - f1_score: 0.4719 - val_loss: 0.1570 - val_f1_score: 0.1381
Epoch 7/60
 - 5s - loss: 0.2467 - f1_score: 0.4778 - val_loss: 0.1712 - val_f1_score: 0.2876
Epoch 8/60
 - 5s - loss: 0.2465 - f1_score: 0.4851 - val_loss: 0.1522 - val_f1_score: 0.1499
Epoch 9/60
 - 5s - loss: 0.2465 - f1_score: 0.4913 - val_loss: 0.1448 - val_f1_score: 0.0339
Epoch 10/60
 - 5s - loss: 0.2453 - f1_score: 0.4747 - val_loss: 0.1464 - val_f1_score: 0.0815
Epoch 11/60
 - 5s - loss: 0.2445 - f1_score: 0.4644 - val_loss: 0.1450 - val_f1_score: 0.1265
Epoch 12/60
 - 5s - loss: 0.2439 - f1_score: 0.4956 - val_loss: 0.1455 - val_f1_score: 0.1084
Epoch 13/60
 - 5s - loss: 0.2437 - f1_score: 0.4735 - val_loss: 0.1437 - val_f1_score: 0.0501
Epoch 14/60
 - 5s - loss: 0.2442 - f1_score: 0.4668 - val_loss: 0.1486 - val_f1_score: 0.0720
Epoch 15/60
 - 5s - loss: 0.2430 - f1_score: 0.4814 - val_loss: 0.1413 - val_f1_score: 0.0172
Epoch 16/60
 - 5s - loss: 0.2422 - f1_score: 0.4703 - val_loss: 0.1666 - val_f1_score: 0.1135
Epoch 17/60
 - 5s - loss: 0.2418 - f1_score: 0.4838 - val_loss: 0.1452 - val_f1_score: 0.0941
Epoch 18/60
 - 5s - loss: 0.2412 - f1_score: 0.4901 - val_loss: 0.1449 - val_f1_score: 0.0652
Epoch 19/60
 - 5s - loss: 0.2431 - f1_score: 0.4648 - val_loss: 0.1668 - val_f1_score: 0.2078
Epoch 20/60
 - 5s - loss: 0.2423 - f1_score: 0.4958 - val_loss: 0.1764 - val_f1_score: 0.1082
Epoch 21/60
 - 5s - loss: 0.2417 - f1_score: 0.4972 - val_loss: 0.1494 - val_f1_score: 0.0582
Epoch 22/60
 - 5s - loss: 0.2417 - f1_score: 0.4722 - val_loss: 0.1475 - val_f1_score: 0.0649
                     0            1    micro avg    macro avg  weighted avg
index                                                                      
precision     0.933252     0.603330     0.893327     0.768291      0.889808
recall        0.944717     0.554455     0.893327     0.749586      0.893327
f1-score      0.938950     0.577861     0.893327     0.758406      0.891401
support    7326.000000  1111.000000  8437.000000  8437.000000   8437.000000
auc           0.907083     0.907082     0.963610     0.907243           NaN
******************** DAP ********************
**********  round  2
load and test: shapes for train and test, X/Y
(41184, 315)
(41184, 2)
(8437, 315)
(8437, 2)
(41184, 8, 25)
(41184, 14)
(41184, 100)
(41184,)
Model: "model_3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
geo_code (InputLayer)           (None, 1)            0                                            
__________________________________________________________________________________________________
main_input (InputLayer)         (None, 8, 25)        0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 1, 128)       119680      geo_code[0][0]                   
__________________________________________________________________________________________________
lstm_5 (LSTM)                   (None, 8, 128)       78848       main_input[0][0]                 
__________________________________________________________________________________________________
geohash_input (InputLayer)      (None, 14)           0                                            
__________________________________________________________________________________________________
nlp_input (InputLayer)          (None, 100)          0                                            
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 128)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
lstm_6 (LSTM)                   (None, 128)          131584      lstm_5[0][0]                     
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 128)          1920        geohash_input[0][0]              
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 128)          12928       nlp_input[0][0]                  
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 128)          16512       flatten_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 512)          0           lstm_6[0][0]                     
                                                                 dense_15[0][0]                   
                                                                 dense_16[0][0]                   
                                                                 dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 512)          262656      concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 256)          131328      dense_18[0][0]                   
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 256)          1024        dense_19[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256)          0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 256)          0           activation_5[0][0]               
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 64)           16448       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 64)           256         dense_20[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64)           0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 2)            130         activation_6[0][0]               
==================================================================================================
Total params: 773,314
Trainable params: 772,674
Non-trainable params: 640
__________________________________________________________________________________________________
None
tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_12:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_13:0' shape=() dtype=int32> fn
Train on 32947 samples, validate on 8237 samples
Epoch 1/60
 - 6s - loss: 0.2886 - f1_score: 0.3253 - val_loss: 0.2978 - val_f1_score: 0.0000e+00
Epoch 2/60
 - 4s - loss: 0.2565 - f1_score: 0.4404 - val_loss: 0.6304 - val_f1_score: 0.2186
Epoch 3/60
 - 4s - loss: 0.2525 - f1_score: 0.4504 - val_loss: 0.1976 - val_f1_score: 0.0086
Epoch 4/60
 - 4s - loss: 0.2505 - f1_score: 0.4680 - val_loss: 0.1530 - val_f1_score: 0.0411
Epoch 5/60
 - 4s - loss: 0.2492 - f1_score: 0.4578 - val_loss: 0.1619 - val_f1_score: 0.0575
Epoch 6/60
 - 4s - loss: 0.2481 - f1_score: 0.4753 - val_loss: 0.2366 - val_f1_score: 0.0487
Epoch 7/60
 - 4s - loss: 0.2489 - f1_score: 0.4577 - val_loss: 0.1420 - val_f1_score: 0.0000e+00
Epoch 8/60
 - 4s - loss: 0.2484 - f1_score: 0.4714 - val_loss: 0.1566 - val_f1_score: 0.0645
Epoch 9/60
 - 4s - loss: 0.2465 - f1_score: 0.4556 - val_loss: 0.1748 - val_f1_score: 0.1006
Epoch 10/60
 - 4s - loss: 0.2445 - f1_score: 0.4705 - val_loss: 0.1410 - val_f1_score: 0.1347
Epoch 11/60
 - 4s - loss: 0.2447 - f1_score: 0.4762 - val_loss: 0.1554 - val_f1_score: 0.1402
Epoch 12/60
 - 4s - loss: 0.2443 - f1_score: 0.4573 - val_loss: 0.1804 - val_f1_score: 0.1678
Epoch 13/60
 - 4s - loss: 0.2427 - f1_score: 0.4858 - val_loss: 0.1710 - val_f1_score: 0.1675
Epoch 14/60
 - 5s - loss: 0.2445 - f1_score: 0.4893 - val_loss: 0.1457 - val_f1_score: 0.0257
Epoch 15/60
 - 5s - loss: 0.2440 - f1_score: 0.4769 - val_loss: 0.1714 - val_f1_score: 0.1757
Epoch 16/60
 - 5s - loss: 0.2413 - f1_score: 0.4693 - val_loss: 0.1555 - val_f1_score: 0.2293
Epoch 17/60
 - 5s - loss: 0.2426 - f1_score: 0.4731 - val_loss: 0.1445 - val_f1_score: 0.0976
Epoch 18/60
 - 5s - loss: 0.2412 - f1_score: 0.4982 - val_loss: 0.1478 - val_f1_score: 0.0977
Epoch 19/60
 - 5s - loss: 0.2417 - f1_score: 0.4575 - val_loss: 0.1541 - val_f1_score: 0.1388
Epoch 20/60
 - 5s - loss: 0.2410 - f1_score: 0.4765 - val_loss: 0.1488 - val_f1_score: 0.0642
Epoch 21/60
 - 5s - loss: 0.2420 - f1_score: 0.4803 - val_loss: 0.1612 - val_f1_score: 0.0708
Epoch 22/60
 - 5s - loss: 0.2405 - f1_score: 0.4776 - val_loss: 0.1574 - val_f1_score: 0.2566
Epoch 23/60
 - 5s - loss: 0.2414 - f1_score: 0.4738 - val_loss: 0.1587 - val_f1_score: 0.0172
Epoch 24/60
 - 5s - loss: 0.2418 - f1_score: 0.4917 - val_loss: 0.1545 - val_f1_score: 0.0718
Epoch 25/60
 - 5s - loss: 0.2403 - f1_score: 0.4915 - val_loss: 0.1533 - val_f1_score: 0.1541
Epoch 26/60
 - 5s - loss: 0.2400 - f1_score: 0.4784 - val_loss: 0.1475 - val_f1_score: 0.0343
Epoch 27/60
 - 5s - loss: 0.2403 - f1_score: 0.4628 - val_loss: 0.1438 - val_f1_score: 0.0087
Epoch 28/60
 - 5s - loss: 0.2407 - f1_score: 0.5039 - val_loss: 0.1930 - val_f1_score: 0.0642
Epoch 29/60
 - 5s - loss: 0.2407 - f1_score: 0.4887 - val_loss: 0.1778 - val_f1_score: 0.0990
Epoch 30/60
 - 4s - loss: 0.2401 - f1_score: 0.4910 - val_loss: 0.1528 - val_f1_score: 0.0000e+00
Epoch 31/60
 - 4s - loss: 0.2404 - f1_score: 0.4676 - val_loss: 0.1513 - val_f1_score: 0.0403
Epoch 32/60
 - 4s - loss: 0.2396 - f1_score: 0.4965 - val_loss: 0.1515 - val_f1_score: 0.0000e+00
Epoch 33/60
 - 4s - loss: 0.2396 - f1_score: 0.4728 - val_loss: 0.1789 - val_f1_score: 0.1222
Epoch 34/60
 - 4s - loss: 0.2393 - f1_score: 0.4793 - val_loss: 0.1595 - val_f1_score: 0.1074
Epoch 35/60
 - 4s - loss: 0.2405 - f1_score: 0.4649 - val_loss: 0.1711 - val_f1_score: 0.2364
Epoch 36/60
 - 4s - loss: 0.2388 - f1_score: 0.4763 - val_loss: 0.1717 - val_f1_score: 0.0681
Epoch 37/60
 - 4s - loss: 0.2386 - f1_score: 0.5036 - val_loss: 0.1422 - val_f1_score: 0.1266
                     0            1    micro avg    macro avg  weighted avg
index                                                                      
precision     0.932534     0.603363     0.893090     0.767949      0.889188
recall        0.945263     0.549055     0.893090     0.747159      0.893090
f1-score      0.938856     0.574929     0.893090     0.756893      0.890933
support    7326.000000  1111.000000  8437.000000  8437.000000   8437.000000
auc           0.909615     0.909620     0.963833     0.909773           NaN
