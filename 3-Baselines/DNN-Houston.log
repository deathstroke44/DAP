Using TensorFlow backend.
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2025-04-16 02:13:19.009316: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2025-04-16 02:13:19.013091: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000000000 Hz
2025-04-16 02:13:19.013352: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f473f4a6f0 executing computations on platform Host. Devices:
2025-04-16 02:13:19.013375: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2025-04-16 02:13:19.084245: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

******************** DNN ********************
**********  round  0
load and test: shapes for train and test, X/Y
(41184, 314)
(41184, 2)
(8437, 314)
(8437, 2)
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_2 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
activation_1 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
activation_2 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn
Train on 32947 samples, validate on 8237 samples
Epoch 1/60
 - 1s - loss: 0.2683 - f1_score: 0.3743 - val_loss: 0.1779 - val_f1_score: 0.2394
Epoch 2/60
 - 1s - loss: 0.2451 - f1_score: 0.4938 - val_loss: 0.1965 - val_f1_score: 0.3304
Epoch 3/60
 - 1s - loss: 0.2439 - f1_score: 0.4953 - val_loss: 0.3303 - val_f1_score: 0.3021
Epoch 4/60
 - 1s - loss: 0.2393 - f1_score: 0.4972 - val_loss: 0.1995 - val_f1_score: 0.3527
Epoch 5/60
 - 1s - loss: 0.2384 - f1_score: 0.4879 - val_loss: 0.1520 - val_f1_score: 0.2297
Epoch 6/60
 - 1s - loss: 0.2363 - f1_score: 0.5063 - val_loss: 0.1420 - val_f1_score: 0.0333
Epoch 7/60
 - 1s - loss: 0.2355 - f1_score: 0.5052 - val_loss: 0.1434 - val_f1_score: 0.2723
Epoch 8/60
 - 1s - loss: 0.2348 - f1_score: 0.5258 - val_loss: 0.1391 - val_f1_score: 0.2173
Epoch 9/60
 - 1s - loss: 0.2334 - f1_score: 0.5232 - val_loss: 0.2373 - val_f1_score: 0.0805
Epoch 10/60
 - 1s - loss: 0.2334 - f1_score: 0.5114 - val_loss: 0.1424 - val_f1_score: 0.1627
Epoch 11/60
 - 1s - loss: 0.2326 - f1_score: 0.5343 - val_loss: 0.1451 - val_f1_score: 0.0881
Epoch 12/60
 - 1s - loss: 0.2306 - f1_score: 0.5013 - val_loss: 0.1378 - val_f1_score: 0.2072
Epoch 13/60
 - 1s - loss: 0.2315 - f1_score: 0.5252 - val_loss: 0.1625 - val_f1_score: 0.3130
Epoch 14/60
 - 1s - loss: 0.2298 - f1_score: 0.5381 - val_loss: 0.1385 - val_f1_score: 0.1402
Epoch 15/60
 - 1s - loss: 0.2293 - f1_score: 0.5278 - val_loss: 0.1630 - val_f1_score: 0.0818
Epoch 16/60
 - 1s - loss: 0.2295 - f1_score: 0.5247 - val_loss: 0.1445 - val_f1_score: 0.1776
Epoch 17/60
 - 1s - loss: 0.2284 - f1_score: 0.5260 - val_loss: 0.1599 - val_f1_score: 0.2820
Epoch 18/60
 - 1s - loss: 0.2270 - f1_score: 0.5180 - val_loss: 0.1370 - val_f1_score: 0.2006
Epoch 19/60
 - 1s - loss: 0.2274 - f1_score: 0.5214 - val_loss: 0.1419 - val_f1_score: 0.0424
                     0            1    micro avg    macro avg  weighted avg
index                                                                      
precision     0.950413     0.499351     0.868081     0.724882      0.891016
recall        0.894758     0.692169     0.868081     0.793464      0.868081
f1-score      0.921746     0.580158     0.868081     0.750952      0.876766
support    7326.000000  1111.000000  8437.000000  8437.000000   8437.000000
auc           0.898089     0.898089     0.949876     0.898261           NaN
******************** DNN ********************
**********  round  1
load and test: shapes for train and test, X/Y
(41184, 314)
(41184, 2)
(8437, 314)
(8437, 2)
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_6 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_3 (Batch (None, 256)               1024      
_________________________________________________________________
activation_3 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
activation_4 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> fn
Train on 32947 samples, validate on 8237 samples
Epoch 1/60
 - 1s - loss: 0.2697 - f1_score: 0.3990 - val_loss: 0.4953 - val_f1_score: 0.0257
Epoch 2/60
 - 1s - loss: 0.2471 - f1_score: 0.4802 - val_loss: 0.2442 - val_f1_score: 0.3132
Epoch 3/60
 - 1s - loss: 0.2444 - f1_score: 0.4915 - val_loss: 0.2081 - val_f1_score: 0.3609
Epoch 4/60
 - 1s - loss: 0.2396 - f1_score: 0.4990 - val_loss: 0.1422 - val_f1_score: 0.2555
Epoch 5/60
 - 1s - loss: 0.2393 - f1_score: 0.5029 - val_loss: 0.1375 - val_f1_score: 0.2427
Epoch 6/60
 - 1s - loss: 0.2362 - f1_score: 0.5168 - val_loss: 0.1411 - val_f1_score: 0.3207
Epoch 7/60
 - 1s - loss: 0.2352 - f1_score: 0.4847 - val_loss: 0.2123 - val_f1_score: 0.3580
Epoch 8/60
 - 1s - loss: 0.2337 - f1_score: 0.5357 - val_loss: 0.1977 - val_f1_score: 0.3247
Epoch 9/60
 - 1s - loss: 0.2336 - f1_score: 0.5231 - val_loss: 0.1492 - val_f1_score: 0.1538
Epoch 10/60
 - 1s - loss: 0.2330 - f1_score: 0.5341 - val_loss: 0.2199 - val_f1_score: 0.3624
Epoch 11/60
 - 1s - loss: 0.2321 - f1_score: 0.5434 - val_loss: 0.1454 - val_f1_score: 0.1292
Epoch 12/60
 - 1s - loss: 0.2309 - f1_score: 0.5288 - val_loss: 0.1446 - val_f1_score: 0.1811
Epoch 13/60
 - 1s - loss: 0.2300 - f1_score: 0.4984 - val_loss: 0.1334 - val_f1_score: 0.1355
Epoch 14/60
 - 1s - loss: 0.2306 - f1_score: 0.5316 - val_loss: 0.1434 - val_f1_score: 0.2917
Epoch 15/60
 - 1s - loss: 0.2288 - f1_score: 0.5324 - val_loss: 0.1558 - val_f1_score: 0.0653
Epoch 16/60
 - 1s - loss: 0.2288 - f1_score: 0.5232 - val_loss: 0.1464 - val_f1_score: 0.1665
Epoch 17/60
 - 1s - loss: 0.2282 - f1_score: 0.5204 - val_loss: 0.1324 - val_f1_score: 0.1075
Epoch 18/60
 - 1s - loss: 0.2281 - f1_score: 0.5350 - val_loss: 0.1546 - val_f1_score: 0.2429
Epoch 19/60
 - 1s - loss: 0.2268 - f1_score: 0.5273 - val_loss: 0.2174 - val_f1_score: 0.0585
Epoch 20/60
 - 1s - loss: 0.2276 - f1_score: 0.5442 - val_loss: 0.1389 - val_f1_score: 0.2644
Epoch 21/60
 - 1s - loss: 0.2257 - f1_score: 0.5526 - val_loss: 0.1375 - val_f1_score: 0.1333
Epoch 22/60
 - 1s - loss: 0.2257 - f1_score: 0.5253 - val_loss: 0.1919 - val_f1_score: 0.0582
Epoch 23/60
 - 1s - loss: 0.2239 - f1_score: 0.5421 - val_loss: 0.1427 - val_f1_score: 0.1881
Epoch 24/60
 - 1s - loss: 0.2241 - f1_score: 0.5314 - val_loss: 0.1379 - val_f1_score: 0.0171
Epoch 25/60
 - 1s - loss: 0.2245 - f1_score: 0.5457 - val_loss: 0.1443 - val_f1_score: 0.2727
                     0            1    micro avg    macro avg  weighted avg
index                                                                      
precision     0.947041     0.488204     0.864051     0.717623      0.886620
recall        0.893393     0.670567     0.864051     0.781980      0.864051
f1-score      0.919435     0.565036     0.864051     0.742236      0.872767
support    7326.000000  1111.000000  8437.000000  8437.000000   8437.000000
auc           0.887481     0.887481     0.943908     0.887663           NaN
******************** DNN ********************
**********  round  2
load and test: shapes for train and test, X/Y
(41184, 314)
(41184, 2)
(8437, 314)
(8437, 2)
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_10 (Dense)             (None, 256)               131328    
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024      
_________________________________________________________________
activation_5 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 64)                16448     
_________________________________________________________________
batch_normalization_6 (Batch (None, 64)                256       
_________________________________________________________________
activation_6 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_12:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_13:0' shape=() dtype=int32> fn
Train on 32947 samples, validate on 8237 samples
Epoch 1/60
 - 2s - loss: 0.2907 - f1_score: 0.3897 - val_loss: 0.3396 - val_f1_score: 0.2771
Epoch 2/60
 - 1s - loss: 0.2463 - f1_score: 0.4642 - val_loss: 0.1631 - val_f1_score: 0.2921
Epoch 3/60
 - 1s - loss: 0.2421 - f1_score: 0.4994 - val_loss: 0.3285 - val_f1_score: 0.3097
Epoch 4/60
 - 1s - loss: 0.2398 - f1_score: 0.5098 - val_loss: 0.1574 - val_f1_score: 0.2601
Epoch 5/60
 - 1s - loss: 0.2371 - f1_score: 0.4997 - val_loss: 0.1826 - val_f1_score: 0.3059
Epoch 6/60
 - 1s - loss: 0.2372 - f1_score: 0.5156 - val_loss: 0.1404 - val_f1_score: 0.1914
Epoch 7/60
 - 1s - loss: 0.2346 - f1_score: 0.4973 - val_loss: 0.1943 - val_f1_score: 0.3633
Epoch 8/60
 - 1s - loss: 0.2335 - f1_score: 0.5212 - val_loss: 0.1412 - val_f1_score: 0.2344
Epoch 9/60
 - 1s - loss: 0.2328 - f1_score: 0.5260 - val_loss: 0.2699 - val_f1_score: 0.3397
Epoch 10/60
 - 1s - loss: 0.2320 - f1_score: 0.5251 - val_loss: 0.1456 - val_f1_score: 0.2003
Epoch 11/60
 - 1s - loss: 0.2314 - f1_score: 0.5112 - val_loss: 0.1760 - val_f1_score: 0.2802
Epoch 12/60
 - 1s - loss: 0.2299 - f1_score: 0.5372 - val_loss: 0.1525 - val_f1_score: 0.2915
Epoch 13/60
 - 1s - loss: 0.2304 - f1_score: 0.5352 - val_loss: 0.1310 - val_f1_score: 0.0953
Epoch 14/60
 - 1s - loss: 0.2297 - f1_score: 0.5436 - val_loss: 0.1561 - val_f1_score: 0.3452
Epoch 15/60
 - 1s - loss: 0.2299 - f1_score: 0.5329 - val_loss: 0.1393 - val_f1_score: 0.2660
Epoch 16/60
 - 1s - loss: 0.2269 - f1_score: 0.5299 - val_loss: 0.1402 - val_f1_score: 0.1086
Epoch 17/60
 - 1s - loss: 0.2272 - f1_score: 0.5547 - val_loss: 0.1378 - val_f1_score: 0.1425
Epoch 18/60
 - 1s - loss: 0.2266 - f1_score: 0.5472 - val_loss: 0.2309 - val_f1_score: 0.0000e+00
Epoch 19/60
 - 1s - loss: 0.2274 - f1_score: 0.5327 - val_loss: 0.1674 - val_f1_score: 0.1351
Epoch 20/60
 - 1s - loss: 0.2276 - f1_score: 0.5414 - val_loss: 0.2057 - val_f1_score: 0.3262
Epoch 21/60
 - 1s - loss: 0.2240 - f1_score: 0.5517 - val_loss: 0.1618 - val_f1_score: 0.3128
Epoch 22/60
 - 1s - loss: 0.2255 - f1_score: 0.5369 - val_loss: 0.1428 - val_f1_score: 0.3110
                     0            1    micro avg    macro avg  weighted avg
index                                                                      
precision     0.951716     0.499039     0.867963     0.725378      0.892107
recall        0.893257     0.701170     0.867963     0.797214      0.867963
f1-score      0.921560     0.583084     0.867963     0.752322      0.876989
support    7326.000000  1111.000000  8437.000000  8437.000000   8437.000000
auc           0.907653     0.907653     0.952601     0.907819           NaN
