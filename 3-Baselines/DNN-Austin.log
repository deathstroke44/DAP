Using TensorFlow backend.
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2025-04-16 02:13:19.346375: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2025-04-16 02:13:19.350574: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000000000 Hz
2025-04-16 02:13:19.350861: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5633177826f0 executing computations on platform Host. Devices:
2025-04-16 02:13:19.350885: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2025-04-16 02:13:19.424905: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

******************** DNN ********************
**********  round  0
load and test: shapes for train and test, X/Y
(22890, 314)
(22890, 2)
(4664, 314)
(4664, 2)
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_2 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
activation_1 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
activation_2 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn
Train on 18312 samples, validate on 4578 samples
Epoch 1/60
 - 1s - loss: 0.3438 - f1_score: 0.3642 - val_loss: 0.1884 - val_f1_score: 0.3447
Epoch 2/60
 - 1s - loss: 0.3077 - f1_score: 0.5436 - val_loss: 0.2618 - val_f1_score: 0.4612
Epoch 3/60
 - 1s - loss: 0.2973 - f1_score: 0.5629 - val_loss: 0.2114 - val_f1_score: 0.3985
Epoch 4/60
 - 1s - loss: 0.2945 - f1_score: 0.5785 - val_loss: 0.2488 - val_f1_score: 0.4895
Epoch 5/60
 - 1s - loss: 0.2913 - f1_score: 0.5850 - val_loss: 0.1899 - val_f1_score: 0.1007
Epoch 6/60
 - 1s - loss: 0.2889 - f1_score: 0.5824 - val_loss: 0.2407 - val_f1_score: 0.0157
Epoch 7/60
 - 1s - loss: 0.2883 - f1_score: 0.5639 - val_loss: 0.2137 - val_f1_score: 0.2727
Epoch 8/60
 - 1s - loss: 0.2847 - f1_score: 0.5994 - val_loss: 0.2111 - val_f1_score: 0.2054
Epoch 9/60
 - 1s - loss: 0.2832 - f1_score: 0.5941 - val_loss: 0.2032 - val_f1_score: 0.3385
Epoch 10/60
 - 1s - loss: 0.2823 - f1_score: 0.5834 - val_loss: 0.2163 - val_f1_score: 0.2621
Epoch 11/60
 - 1s - loss: 0.2804 - f1_score: 0.5774 - val_loss: 0.2380 - val_f1_score: 0.3692
Epoch 12/60
 - 1s - loss: 0.2778 - f1_score: 0.5989 - val_loss: 0.2104 - val_f1_score: 0.1113
Epoch 13/60
 - 1s - loss: 0.2771 - f1_score: 0.5852 - val_loss: 0.2316 - val_f1_score: 0.2198
Epoch 14/60
 - 1s - loss: 0.2771 - f1_score: 0.5999 - val_loss: 0.1917 - val_f1_score: 0.1076
Epoch 15/60
 - 1s - loss: 0.2764 - f1_score: 0.6093 - val_loss: 0.1795 - val_f1_score: 0.1756
Epoch 16/60
 - 1s - loss: 0.2733 - f1_score: 0.6120 - val_loss: 0.1982 - val_f1_score: 0.2240
Epoch 17/60
 - 1s - loss: 0.2737 - f1_score: 0.6052 - val_loss: 0.2368 - val_f1_score: 0.1666
Epoch 18/60
 - 1s - loss: 0.2706 - f1_score: 0.5991 - val_loss: 0.1995 - val_f1_score: 0.2351
Epoch 19/60
 - 1s - loss: 0.2685 - f1_score: 0.6239 - val_loss: 0.2433 - val_f1_score: 0.3336
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.946013    0.576046     0.862564     0.761029      0.882475
recall        0.884546    0.756554     0.862564     0.820550      0.862564
f1-score      0.914247    0.654074     0.862564     0.784161      0.869565
support    3863.000000  801.000000  4664.000000  4664.000000   4664.000000
auc           0.903277    0.903277     0.942069     0.903547           NaN
******************** DNN ********************
**********  round  1
load and test: shapes for train and test, X/Y
(22890, 314)
(22890, 2)
(4664, 314)
(4664, 2)
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_6 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_3 (Batch (None, 256)               1024      
_________________________________________________________________
activation_3 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
activation_4 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> fn
Train on 18312 samples, validate on 4578 samples
Epoch 1/60
 - 1s - loss: 0.3876 - f1_score: 0.3858 - val_loss: 0.2883 - val_f1_score: 0.1109
Epoch 2/60
 - 1s - loss: 0.3077 - f1_score: 0.5111 - val_loss: 0.2202 - val_f1_score: 0.0984
Epoch 3/60
 - 1s - loss: 0.3014 - f1_score: 0.5514 - val_loss: 0.1940 - val_f1_score: 0.2184
Epoch 4/60
 - 1s - loss: 0.2943 - f1_score: 0.5646 - val_loss: 0.1869 - val_f1_score: 0.1038
Epoch 5/60
 - 1s - loss: 0.2943 - f1_score: 0.5524 - val_loss: 0.1857 - val_f1_score: 0.0843
Epoch 6/60
 - 1s - loss: 0.2914 - f1_score: 0.5890 - val_loss: 0.2011 - val_f1_score: 0.3778
Epoch 7/60
 - 1s - loss: 0.2909 - f1_score: 0.5790 - val_loss: 0.3003 - val_f1_score: 0.4388
Epoch 8/60
 - 1s - loss: 0.2855 - f1_score: 0.5764 - val_loss: 0.2043 - val_f1_score: 0.2642
Epoch 9/60
 - 1s - loss: 0.2841 - f1_score: 0.6062 - val_loss: 0.2066 - val_f1_score: 0.1300
Epoch 10/60
 - 1s - loss: 0.2827 - f1_score: 0.5919 - val_loss: 0.1946 - val_f1_score: 0.4033
Epoch 11/60
 - 1s - loss: 0.2821 - f1_score: 0.6086 - val_loss: 0.1843 - val_f1_score: 0.2701
Epoch 12/60
 - 1s - loss: 0.2809 - f1_score: 0.5952 - val_loss: 0.2438 - val_f1_score: 0.0000e+00
Epoch 13/60
 - 1s - loss: 0.2793 - f1_score: 0.5938 - val_loss: 0.1837 - val_f1_score: 0.1284
Epoch 14/60
 - 1s - loss: 0.2786 - f1_score: 0.6013 - val_loss: 0.3003 - val_f1_score: 0.3709
Epoch 15/60
 - 1s - loss: 0.2770 - f1_score: 0.6040 - val_loss: 0.2473 - val_f1_score: 0.0408
Epoch 16/60
 - 1s - loss: 0.2753 - f1_score: 0.5992 - val_loss: 0.2449 - val_f1_score: 0.3966
Epoch 17/60
 - 1s - loss: 0.2745 - f1_score: 0.5851 - val_loss: 0.2007 - val_f1_score: 0.0769
Epoch 18/60
 - 1s - loss: 0.2714 - f1_score: 0.5853 - val_loss: 0.2201 - val_f1_score: 0.3528
Epoch 19/60
 - 1s - loss: 0.2715 - f1_score: 0.6032 - val_loss: 0.2514 - val_f1_score: 0.0909
Epoch 20/60
 - 1s - loss: 0.2725 - f1_score: 0.6002 - val_loss: 0.2630 - val_f1_score: 0.4372
Epoch 21/60
 - 1s - loss: 0.2697 - f1_score: 0.5916 - val_loss: 0.1926 - val_f1_score: 0.0581
Epoch 22/60
 - 1s - loss: 0.2701 - f1_score: 0.5915 - val_loss: 0.2133 - val_f1_score: 0.3457
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.935020    0.612761     0.872213     0.773891      0.879675
recall        0.908879    0.695381     0.872213     0.802130      0.872213
f1-score      0.921764    0.651462     0.872213     0.786613      0.875342
support    3863.000000  801.000000  4664.000000  4664.000000   4664.000000
auc           0.898975    0.898975     0.943171     0.899240           NaN
******************** DNN ********************
**********  round  2
load and test: shapes for train and test, X/Y
(22890, 314)
(22890, 2)
(4664, 314)
(4664, 2)
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_10 (Dense)             (None, 256)               131328    
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024      
_________________________________________________________________
activation_5 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 64)                16448     
_________________________________________________________________
batch_normalization_6 (Batch (None, 64)                256       
_________________________________________________________________
activation_6 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_12:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_13:0' shape=() dtype=int32> fn
Train on 18312 samples, validate on 4578 samples
Epoch 1/60
 - 1s - loss: 0.3628 - f1_score: 0.3761 - val_loss: 0.2582 - val_f1_score: 0.1449
Epoch 2/60
 - 1s - loss: 0.3076 - f1_score: 0.5385 - val_loss: 0.2135 - val_f1_score: 0.2952
Epoch 3/60
 - 1s - loss: 0.3017 - f1_score: 0.5531 - val_loss: 0.2340 - val_f1_score: 0.0919
Epoch 4/60
 - 1s - loss: 0.2946 - f1_score: 0.5952 - val_loss: 0.2391 - val_f1_score: 0.0402
Epoch 5/60
 - 1s - loss: 0.2922 - f1_score: 0.5792 - val_loss: 0.1851 - val_f1_score: 0.1529
Epoch 6/60
 - 1s - loss: 0.2904 - f1_score: 0.5966 - val_loss: 0.2052 - val_f1_score: 0.2945
Epoch 7/60
 - 1s - loss: 0.2862 - f1_score: 0.5916 - val_loss: 0.2046 - val_f1_score: 0.2260
Epoch 8/60
 - 1s - loss: 0.2851 - f1_score: 0.5726 - val_loss: 0.2149 - val_f1_score: 0.0837
Epoch 9/60
 - 1s - loss: 0.2834 - f1_score: 0.5961 - val_loss: 0.2254 - val_f1_score: 0.0409
Epoch 10/60
 - 1s - loss: 0.2806 - f1_score: 0.6093 - val_loss: 0.1883 - val_f1_score: 0.1885
Epoch 11/60
 - 1s - loss: 0.2808 - f1_score: 0.6093 - val_loss: 0.1958 - val_f1_score: 0.0411
Epoch 12/60
 - 1s - loss: 0.2797 - f1_score: 0.6025 - val_loss: 0.2035 - val_f1_score: 0.3481
Epoch 13/60
 - 1s - loss: 0.2790 - f1_score: 0.5930 - val_loss: 0.2107 - val_f1_score: 0.1982
Epoch 14/60
 - 1s - loss: 0.2762 - f1_score: 0.5997 - val_loss: 0.2266 - val_f1_score: 0.1179
Epoch 15/60
 - 1s - loss: 0.2741 - f1_score: 0.5979 - val_loss: 0.1972 - val_f1_score: 0.1421
Epoch 16/60
 - 1s - loss: 0.2745 - f1_score: 0.6026 - val_loss: 0.1972 - val_f1_score: 0.3132
Epoch 17/60
 - 1s - loss: 0.2731 - f1_score: 0.6199 - val_loss: 0.1894 - val_f1_score: 0.1475
Epoch 18/60
 - 1s - loss: 0.2708 - f1_score: 0.5942 - val_loss: 0.1948 - val_f1_score: 0.1920
Epoch 19/60
 - 1s - loss: 0.2727 - f1_score: 0.6017 - val_loss: 0.2122 - val_f1_score: 0.2346
Epoch 20/60
 - 1s - loss: 0.2720 - f1_score: 0.6015 - val_loss: 0.1950 - val_f1_score: 0.3502
Epoch 21/60
 - 1s - loss: 0.2690 - f1_score: 0.6227 - val_loss: 0.2204 - val_f1_score: 0.1313
Epoch 22/60
 - 1s - loss: 0.2667 - f1_score: 0.6446 - val_loss: 0.2056 - val_f1_score: 0.3556
Epoch 23/60
 - 1s - loss: 0.2658 - f1_score: 0.6100 - val_loss: 0.2422 - val_f1_score: 0.2901
Epoch 24/60
 - 1s - loss: 0.2686 - f1_score: 0.6349 - val_loss: 0.2976 - val_f1_score: 0.3739
Epoch 25/60
 - 1s - loss: 0.2662 - f1_score: 0.6376 - val_loss: 0.2987 - val_f1_score: 0.4010
Epoch 26/60
 - 1s - loss: 0.2664 - f1_score: 0.6212 - val_loss: 0.1968 - val_f1_score: 0.2648
Epoch 27/60
 - 1s - loss: 0.2619 - f1_score: 0.6222 - val_loss: 0.2068 - val_f1_score: 0.2905
Epoch 28/60
 - 1s - loss: 0.2588 - f1_score: 0.6437 - val_loss: 0.2149 - val_f1_score: 0.2293
Epoch 29/60
 - 1s - loss: 0.2600 - f1_score: 0.6396 - val_loss: 0.2530 - val_f1_score: 0.1381
Epoch 30/60
 - 1s - loss: 0.2562 - f1_score: 0.6296 - val_loss: 0.2059 - val_f1_score: 0.1955
Epoch 31/60
 - 1s - loss: 0.2591 - f1_score: 0.6321 - val_loss: 0.2884 - val_f1_score: 0.1896
Epoch 32/60
 - 1s - loss: 0.2554 - f1_score: 0.6537 - val_loss: 0.2472 - val_f1_score: 0.1187
Epoch 33/60
 - 1s - loss: 0.2561 - f1_score: 0.6349 - val_loss: 0.2405 - val_f1_score: 0.3281
Epoch 34/60
 - 1s - loss: 0.2514 - f1_score: 0.6538 - val_loss: 0.2041 - val_f1_score: 0.1925
Epoch 35/60
 - 1s - loss: 0.2544 - f1_score: 0.6218 - val_loss: 0.2562 - val_f1_score: 0.2620
Epoch 36/60
 - 1s - loss: 0.2514 - f1_score: 0.6430 - val_loss: 0.2328 - val_f1_score: 0.2960
Epoch 37/60
 - 1s - loss: 0.2500 - f1_score: 0.6491 - val_loss: 0.3762 - val_f1_score: 0.1160
Epoch 38/60
 - 1s - loss: 0.2500 - f1_score: 0.6631 - val_loss: 0.2784 - val_f1_score: 0.3436
Epoch 39/60
 - 1s - loss: 0.2470 - f1_score: 0.6447 - val_loss: 0.2314 - val_f1_score: 0.2754
Epoch 40/60
 - 1s - loss: 0.2434 - f1_score: 0.6541 - val_loss: 0.2421 - val_f1_score: 0.2502
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.932031    0.537864     0.844983     0.734947      0.864336
recall        0.876780    0.691635     0.844983     0.784208      0.844983
f1-score      0.903561    0.605134     0.844983     0.754348      0.852309
support    3863.000000  801.000000  4664.000000  4664.000000   4664.000000
auc           0.888655    0.888656     0.928957     0.888927           NaN
