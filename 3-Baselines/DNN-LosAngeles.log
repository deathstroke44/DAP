Using TensorFlow backend.
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2025-04-16 02:13:18.831850: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2025-04-16 02:13:18.835586: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000000000 Hz
2025-04-16 02:13:18.835857: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561d6e9c5700 executing computations on platform Host. Devices:
2025-04-16 02:13:18.835882: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2025-04-16 02:13:18.904251: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

******************** DNN ********************
**********  round  0
load and test: shapes for train and test, X/Y
(30862, 314)
(30862, 2)
(6132, 314)
(6132, 2)
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_2 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
activation_1 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
activation_2 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn
Train on 24689 samples, validate on 6173 samples
Epoch 1/60
 - 1s - loss: 0.4767 - f1_score: 0.2886 - val_loss: 0.4278 - val_f1_score: 0.2261
Epoch 2/60
 - 1s - loss: 0.4362 - f1_score: 0.3856 - val_loss: 0.3675 - val_f1_score: 0.3028
Epoch 3/60
 - 1s - loss: 0.4299 - f1_score: 0.4328 - val_loss: 0.4410 - val_f1_score: 0.3538
Epoch 4/60
 - 1s - loss: 0.4246 - f1_score: 0.4276 - val_loss: 0.3696 - val_f1_score: 0.3235
Epoch 5/60
 - 1s - loss: 0.4238 - f1_score: 0.4264 - val_loss: 0.4186 - val_f1_score: 0.3333
Epoch 6/60
 - 1s - loss: 0.4169 - f1_score: 0.4403 - val_loss: 0.3314 - val_f1_score: 0.0541
Epoch 7/60
 - 1s - loss: 0.4174 - f1_score: 0.4446 - val_loss: 0.3270 - val_f1_score: 0.0651
Epoch 8/60
 - 1s - loss: 0.4144 - f1_score: 0.4553 - val_loss: 0.3545 - val_f1_score: 0.0035
Epoch 9/60
 - 1s - loss: 0.4133 - f1_score: 0.4600 - val_loss: 0.3277 - val_f1_score: 0.0245
Epoch 10/60
 - 1s - loss: 0.4130 - f1_score: 0.4606 - val_loss: 0.3360 - val_f1_score: 0.1376
Epoch 11/60
 - 1s - loss: 0.4106 - f1_score: 0.4641 - val_loss: 0.4409 - val_f1_score: 0.3880
Epoch 12/60
 - 1s - loss: 0.4103 - f1_score: 0.4627 - val_loss: 0.3425 - val_f1_score: 0.1907
Epoch 13/60
 - 1s - loss: 0.4094 - f1_score: 0.4569 - val_loss: 0.3462 - val_f1_score: 0.0655
Epoch 14/60
 - 1s - loss: 0.4076 - f1_score: 0.4883 - val_loss: 0.3301 - val_f1_score: 0.1176
Epoch 15/60
 - 1s - loss: 0.4086 - f1_score: 0.4556 - val_loss: 0.4673 - val_f1_score: 0.3885
Epoch 16/60
 - 1s - loss: 0.4069 - f1_score: 0.4654 - val_loss: 0.3377 - val_f1_score: 0.0962
Epoch 17/60
 - 1s - loss: 0.4056 - f1_score: 0.4727 - val_loss: 0.3749 - val_f1_score: 0.3954
Epoch 18/60
 - 1s - loss: 0.4038 - f1_score: 0.4892 - val_loss: 0.3887 - val_f1_score: 0.0047
Epoch 19/60
 - 1s - loss: 0.4034 - f1_score: 0.4794 - val_loss: 0.3338 - val_f1_score: 0.0457
Epoch 20/60
 - 1s - loss: 0.4022 - f1_score: 0.4661 - val_loss: 0.3583 - val_f1_score: 0.1411
Epoch 21/60
 - 1s - loss: 0.4026 - f1_score: 0.4786 - val_loss: 0.3485 - val_f1_score: 0.0104
Epoch 22/60
 - 1s - loss: 0.4010 - f1_score: 0.4899 - val_loss: 0.3473 - val_f1_score: 0.1181
Epoch 23/60
 - 1s - loss: 0.4009 - f1_score: 0.4692 - val_loss: 0.3681 - val_f1_score: 0.2601
Epoch 24/60
 - 1s - loss: 0.4010 - f1_score: 0.4993 - val_loss: 0.3343 - val_f1_score: 0.1241
Epoch 25/60
 - 1s - loss: 0.3983 - f1_score: 0.4923 - val_loss: 0.3297 - val_f1_score: 0.0934
Epoch 26/60
 - 1s - loss: 0.3988 - f1_score: 0.5067 - val_loss: 0.3754 - val_f1_score: 0.1696
Epoch 27/60
 - 1s - loss: 0.3983 - f1_score: 0.5059 - val_loss: 0.4669 - val_f1_score: 0.3289
Epoch 28/60
 - 1s - loss: 0.3957 - f1_score: 0.5179 - val_loss: 0.3430 - val_f1_score: 0.2693
Epoch 29/60
 - 1s - loss: 0.3956 - f1_score: 0.4817 - val_loss: 0.3436 - val_f1_score: 0.2897
Epoch 30/60
 - 1s - loss: 0.3953 - f1_score: 0.5155 - val_loss: 0.3745 - val_f1_score: 0.1311
Epoch 31/60
 - 1s - loss: 0.3935 - f1_score: 0.5079 - val_loss: 0.3356 - val_f1_score: 0.0315
Epoch 32/60
 - 1s - loss: 0.3926 - f1_score: 0.5090 - val_loss: 0.3820 - val_f1_score: 0.0058
                     0            1    micro avg    macro avg  weighted avg
index                                                                      
precision     0.904786     0.450472     0.747717     0.677629      0.805729
recall        0.757039     0.714286     0.747717     0.735662      0.747717
f1-score      0.824344     0.552502     0.747717     0.688423      0.765073
support    4795.000000  1337.000000  6132.000000  6132.000000   6132.000000
auc           0.814568     0.814568     0.849815     0.814768           NaN
******************** DNN ********************
**********  round  1
load and test: shapes for train and test, X/Y
(30862, 314)
(30862, 2)
(6132, 314)
(6132, 2)
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_6 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_3 (Batch (None, 256)               1024      
_________________________________________________________________
activation_3 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
activation_4 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> fn
Train on 24689 samples, validate on 6173 samples
Epoch 1/60
 - 1s - loss: 0.4870 - f1_score: 0.3228 - val_loss: 0.8754 - val_f1_score: 0.1700
Epoch 2/60
 - 1s - loss: 0.4352 - f1_score: 0.3735 - val_loss: 0.4114 - val_f1_score: 0.3612
Epoch 3/60
 - 1s - loss: 0.4289 - f1_score: 0.4174 - val_loss: 0.3318 - val_f1_score: 0.2051
Epoch 4/60
 - 1s - loss: 0.4266 - f1_score: 0.4337 - val_loss: 0.3766 - val_f1_score: 0.3091
Epoch 5/60
 - 1s - loss: 0.4224 - f1_score: 0.4338 - val_loss: 0.3311 - val_f1_score: 0.0071
Epoch 6/60
 - 1s - loss: 0.4199 - f1_score: 0.4255 - val_loss: 0.3207 - val_f1_score: 0.2679
Epoch 7/60
 - 1s - loss: 0.4155 - f1_score: 0.4619 - val_loss: 0.3192 - val_f1_score: 0.0551
Epoch 8/60
 - 1s - loss: 0.4138 - f1_score: 0.4453 - val_loss: 0.4074 - val_f1_score: 0.3648
Epoch 9/60
 - 1s - loss: 0.4151 - f1_score: 0.4571 - val_loss: 0.4025 - val_f1_score: 0.0191
Epoch 10/60
 - 1s - loss: 0.4137 - f1_score: 0.4644 - val_loss: 0.3552 - val_f1_score: 0.2514
Epoch 11/60
 - 1s - loss: 0.4085 - f1_score: 0.4521 - val_loss: 0.3322 - val_f1_score: 0.1467
Epoch 12/60
 - 1s - loss: 0.4082 - f1_score: 0.4469 - val_loss: 0.3626 - val_f1_score: 0.0146
Epoch 13/60
 - 1s - loss: 0.4084 - f1_score: 0.4551 - val_loss: 0.3599 - val_f1_score: 0.1735
Epoch 14/60
 - 1s - loss: 0.4073 - f1_score: 0.4582 - val_loss: 0.3494 - val_f1_score: 0.2793
Epoch 15/60
 - 1s - loss: 0.4065 - f1_score: 0.4529 - val_loss: 0.3521 - val_f1_score: 0.0836
Epoch 16/60
 - 1s - loss: 0.4059 - f1_score: 0.4752 - val_loss: 0.3375 - val_f1_score: 0.1180
Epoch 17/60
 - 1s - loss: 0.4061 - f1_score: 0.4452 - val_loss: 0.3351 - val_f1_score: 0.1059
Epoch 18/60
 - 1s - loss: 0.4034 - f1_score: 0.4869 - val_loss: 0.3214 - val_f1_score: 0.2171
Epoch 19/60
 - 1s - loss: 0.4011 - f1_score: 0.4604 - val_loss: 0.3374 - val_f1_score: 0.1116
Epoch 20/60
 - 1s - loss: 0.4032 - f1_score: 0.4739 - val_loss: 0.3330 - val_f1_score: 0.0591
Epoch 21/60
 - 1s - loss: 0.4023 - f1_score: 0.4946 - val_loss: 0.3485 - val_f1_score: 0.2814
Epoch 22/60
 - 1s - loss: 0.4010 - f1_score: 0.4872 - val_loss: 0.3526 - val_f1_score: 0.1329
Epoch 23/60
 - 1s - loss: 0.3997 - f1_score: 0.4779 - val_loss: 0.3320 - val_f1_score: 0.1501
                     0            1    micro avg    macro avg  weighted avg
index                                                                      
precision     0.888212     0.433366     0.737932     0.660789      0.789039
recall        0.760584     0.656694     0.737932     0.708639      0.737932
f1-score      0.819458     0.522153     0.737932     0.670806      0.754635
support    4795.000000  1337.000000  6132.000000  6132.000000   6132.000000
auc           0.795745     0.795745     0.845484     0.795949           NaN
******************** DNN ********************
**********  round  2
load and test: shapes for train and test, X/Y
(30862, 314)
(30862, 2)
(6132, 314)
(6132, 2)
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_10 (Dense)             (None, 256)               131328    
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024      
_________________________________________________________________
activation_5 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 64)                16448     
_________________________________________________________________
batch_normalization_6 (Batch (None, 64)                256       
_________________________________________________________________
activation_6 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_12:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_13:0' shape=() dtype=int32> fn
Train on 24689 samples, validate on 6173 samples
Epoch 1/60
 - 1s - loss: 0.4723 - f1_score: 0.2976 - val_loss: 0.7394 - val_f1_score: 0.3011
Epoch 2/60
 - 1s - loss: 0.4340 - f1_score: 0.4071 - val_loss: 0.5372 - val_f1_score: 0.3422
Epoch 3/60
 - 1s - loss: 0.4277 - f1_score: 0.4054 - val_loss: 0.3936 - val_f1_score: 0.2964
Epoch 4/60
 - 1s - loss: 0.4232 - f1_score: 0.4415 - val_loss: 0.4016 - val_f1_score: 0.3465
Epoch 5/60
 - 1s - loss: 0.4198 - f1_score: 0.4437 - val_loss: 0.3872 - val_f1_score: 0.3269
Epoch 6/60
 - 1s - loss: 0.4177 - f1_score: 0.4396 - val_loss: 0.3377 - val_f1_score: 0.0109
Epoch 7/60
 - 1s - loss: 0.4165 - f1_score: 0.4492 - val_loss: 0.3349 - val_f1_score: 0.0320
Epoch 8/60
 - 1s - loss: 0.4138 - f1_score: 0.4384 - val_loss: 0.3423 - val_f1_score: 0.0766
Epoch 9/60
 - 1s - loss: 0.4144 - f1_score: 0.4599 - val_loss: 0.3462 - val_f1_score: 0.0036
Epoch 10/60
 - 1s - loss: 0.4132 - f1_score: 0.4470 - val_loss: 0.3271 - val_f1_score: 0.1468
Epoch 11/60
 - 1s - loss: 0.4089 - f1_score: 0.4630 - val_loss: 0.3309 - val_f1_score: 0.0397
Epoch 12/60
 - 1s - loss: 0.4091 - f1_score: 0.4615 - val_loss: 0.4200 - val_f1_score: 0.3445
Epoch 13/60
 - 1s - loss: 0.4078 - f1_score: 0.4836 - val_loss: 0.3827 - val_f1_score: 0.2117
Epoch 14/60
 - 1s - loss: 0.4074 - f1_score: 0.4682 - val_loss: 0.3320 - val_f1_score: 0.0229
Epoch 15/60
 - 1s - loss: 0.4067 - f1_score: 0.4722 - val_loss: 0.3462 - val_f1_score: 0.1677
Epoch 16/60
 - 1s - loss: 0.4039 - f1_score: 0.4657 - val_loss: 0.3445 - val_f1_score: 0.0090
Epoch 17/60
 - 1s - loss: 0.4048 - f1_score: 0.4672 - val_loss: 0.3324 - val_f1_score: 0.1400
Epoch 18/60
 - 1s - loss: 0.4034 - f1_score: 0.4854 - val_loss: 0.3223 - val_f1_score: 0.0980
Epoch 19/60
 - 1s - loss: 0.4009 - f1_score: 0.4798 - val_loss: 0.3705 - val_f1_score: 0.3629
Epoch 20/60
 - 1s - loss: 0.3996 - f1_score: 0.4675 - val_loss: 0.3330 - val_f1_score: 0.0398
Epoch 21/60
 - 1s - loss: 0.4010 - f1_score: 0.4959 - val_loss: 0.3902 - val_f1_score: 0.1164
Epoch 22/60
 - 1s - loss: 0.3995 - f1_score: 0.4971 - val_loss: 0.3636 - val_f1_score: 0.2438
Epoch 23/60
 - 1s - loss: 0.3978 - f1_score: 0.4993 - val_loss: 0.3347 - val_f1_score: 0.1888
Epoch 24/60
 - 1s - loss: 0.3985 - f1_score: 0.4985 - val_loss: 0.3658 - val_f1_score: 0.0428
Epoch 25/60
 - 1s - loss: 0.3959 - f1_score: 0.4897 - val_loss: 0.3251 - val_f1_score: 0.1669
Epoch 26/60
 - 1s - loss: 0.3954 - f1_score: 0.5002 - val_loss: 0.3729 - val_f1_score: 0.0028
Epoch 27/60
 - 1s - loss: 0.3972 - f1_score: 0.4981 - val_loss: 0.3476 - val_f1_score: 0.0149
Epoch 28/60
 - 1s - loss: 0.3930 - f1_score: 0.4927 - val_loss: 0.3568 - val_f1_score: 0.0847
Epoch 29/60
 - 1s - loss: 0.3922 - f1_score: 0.5023 - val_loss: 0.3869 - val_f1_score: 0.2933
Epoch 30/60
 - 1s - loss: 0.3933 - f1_score: 0.5025 - val_loss: 0.3315 - val_f1_score: 0.0181
Epoch 31/60
 - 1s - loss: 0.3903 - f1_score: 0.5098 - val_loss: 0.3521 - val_f1_score: 0.0153
Epoch 32/60
 - 1s - loss: 0.3897 - f1_score: 0.5011 - val_loss: 0.3570 - val_f1_score: 0.0187
Epoch 33/60
 - 1s - loss: 0.3895 - f1_score: 0.5044 - val_loss: 0.3609 - val_f1_score: 0.1508
Epoch 34/60
 - 1s - loss: 0.3876 - f1_score: 0.5117 - val_loss: 0.3399 - val_f1_score: 0.2029
                     0            1    micro avg    macro avg  weighted avg
index                                                                      
precision     0.874162     0.500995     0.782453     0.687579      0.792798
recall        0.843170     0.564697     0.782453     0.703934      0.782453
f1-score      0.858386     0.530942     0.782453     0.694664      0.786992
support    4795.000000  1337.000000  6132.000000  6132.000000   6132.000000
auc           0.790333     0.790333     0.866610     0.790533           NaN
