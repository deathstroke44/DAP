Using TensorFlow backend.
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2025-04-16 02:13:19.291161: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2025-04-16 02:13:19.295228: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000000000 Hz
2025-04-16 02:13:19.295521: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5585998f16f0 executing computations on platform Host. Devices:
2025-04-16 02:13:19.295544: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2025-04-16 02:13:19.364653: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

******************** DNN ********************
**********  round  0
load and test: shapes for train and test, X/Y
(21102, 314)
(21102, 2)
(4385, 314)
(4385, 2)
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_2 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
activation_1 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
activation_2 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn
Train on 16881 samples, validate on 4221 samples
Epoch 1/60
 - 1s - loss: 0.4038 - f1_score: 0.4339 - val_loss: 1.0946 - val_f1_score: 0.4413
Epoch 2/60
 - 1s - loss: 0.3493 - f1_score: 0.5923 - val_loss: 0.5910 - val_f1_score: 0.4804
Epoch 3/60
 - 1s - loss: 0.3469 - f1_score: 0.6119 - val_loss: 0.4095 - val_f1_score: 0.5168
Epoch 4/60
 - 1s - loss: 0.3416 - f1_score: 0.6038 - val_loss: 0.3350 - val_f1_score: 0.5167
Epoch 5/60
 - 1s - loss: 0.3354 - f1_score: 0.6363 - val_loss: 0.3713 - val_f1_score: 0.4782
Epoch 6/60
 - 1s - loss: 0.3338 - f1_score: 0.6179 - val_loss: 0.3688 - val_f1_score: 0.4938
Epoch 7/60
 - 1s - loss: 0.3330 - f1_score: 0.6340 - val_loss: 0.3470 - val_f1_score: 0.5029
Epoch 8/60
 - 1s - loss: 0.3288 - f1_score: 0.6385 - val_loss: 0.3607 - val_f1_score: 0.5068
Epoch 9/60
 - 1s - loss: 0.3307 - f1_score: 0.6316 - val_loss: 0.3251 - val_f1_score: 0.3956
Epoch 10/60
 - 1s - loss: 0.3293 - f1_score: 0.6260 - val_loss: 0.2932 - val_f1_score: 0.3886
Epoch 11/60
 - 1s - loss: 0.3258 - f1_score: 0.6295 - val_loss: 0.3085 - val_f1_score: 0.5170
Epoch 12/60
 - 1s - loss: 0.3249 - f1_score: 0.6409 - val_loss: 0.3080 - val_f1_score: 0.5063
Epoch 13/60
 - 1s - loss: 0.3220 - f1_score: 0.6396 - val_loss: 0.2924 - val_f1_score: 0.4285
Epoch 14/60
 - 1s - loss: 0.3198 - f1_score: 0.6369 - val_loss: 0.3089 - val_f1_score: 0.5009
Epoch 15/60
 - 1s - loss: 0.3202 - f1_score: 0.6516 - val_loss: 0.3440 - val_f1_score: 0.4541
Epoch 16/60
 - 1s - loss: 0.3174 - f1_score: 0.6396 - val_loss: 0.3828 - val_f1_score: 0.1743
Epoch 17/60
 - 1s - loss: 0.3165 - f1_score: 0.6492 - val_loss: 0.3410 - val_f1_score: 0.5235
Epoch 18/60
 - 1s - loss: 0.3186 - f1_score: 0.6516 - val_loss: 0.3289 - val_f1_score: 0.4729
Epoch 19/60
 - 1s - loss: 0.3160 - f1_score: 0.6443 - val_loss: 0.3029 - val_f1_score: 0.4710
Epoch 20/60
 - 1s - loss: 0.3129 - f1_score: 0.6678 - val_loss: 0.3388 - val_f1_score: 0.3918
Epoch 21/60
 - 1s - loss: 0.3166 - f1_score: 0.6465 - val_loss: 0.3607 - val_f1_score: 0.4920
Epoch 22/60
 - 1s - loss: 0.3116 - f1_score: 0.6364 - val_loss: 0.3557 - val_f1_score: 0.5011
Epoch 23/60
 - 0s - loss: 0.3103 - f1_score: 0.6664 - val_loss: 0.3431 - val_f1_score: 0.4437
Epoch 24/60
 - 1s - loss: 0.3107 - f1_score: 0.6550 - val_loss: 0.3054 - val_f1_score: 0.4916
Epoch 25/60
 - 1s - loss: 0.3100 - f1_score: 0.6617 - val_loss: 0.4155 - val_f1_score: 0.5055
Epoch 26/60
 - 1s - loss: 0.3074 - f1_score: 0.6589 - val_loss: 0.3697 - val_f1_score: 0.2927
Epoch 27/60
 - 1s - loss: 0.3053 - f1_score: 0.6711 - val_loss: 0.2960 - val_f1_score: 0.3990
Epoch 28/60
 - 1s - loss: 0.3053 - f1_score: 0.6669 - val_loss: 0.3632 - val_f1_score: 0.4833
Epoch 29/60
 - 1s - loss: 0.3045 - f1_score: 0.6786 - val_loss: 0.3290 - val_f1_score: 0.4980
Epoch 30/60
 - 1s - loss: 0.3043 - f1_score: 0.6694 - val_loss: 0.3335 - val_f1_score: 0.5018
Epoch 31/60
 - 1s - loss: 0.2989 - f1_score: 0.6590 - val_loss: 0.3967 - val_f1_score: 0.5260
Epoch 32/60
 - 1s - loss: 0.3026 - f1_score: 0.6621 - val_loss: 0.3501 - val_f1_score: 0.4918
Epoch 33/60
 - 1s - loss: 0.2991 - f1_score: 0.6670 - val_loss: 0.4341 - val_f1_score: 0.5111
Epoch 34/60
 - 1s - loss: 0.2976 - f1_score: 0.6733 - val_loss: 0.3403 - val_f1_score: 0.4630
Epoch 35/60
 - 1s - loss: 0.2942 - f1_score: 0.6684 - val_loss: 0.3348 - val_f1_score: 0.4841
Epoch 36/60
 - 1s - loss: 0.2934 - f1_score: 0.6699 - val_loss: 0.3628 - val_f1_score: 0.5058
Epoch 37/60
 - 1s - loss: 0.2931 - f1_score: 0.6947 - val_loss: 0.3326 - val_f1_score: 0.3422
Epoch 38/60
 - 1s - loss: 0.2884 - f1_score: 0.6919 - val_loss: 0.3703 - val_f1_score: 0.4907
Epoch 39/60
 - 1s - loss: 0.2879 - f1_score: 0.6936 - val_loss: 0.3437 - val_f1_score: 0.5228
Epoch 40/60
 - 1s - loss: 0.2872 - f1_score: 0.6903 - val_loss: 0.3925 - val_f1_score: 0.3884
Epoch 41/60
 - 1s - loss: 0.2862 - f1_score: 0.6831 - val_loss: 0.3783 - val_f1_score: 0.4312
Epoch 42/60
 - 1s - loss: 0.2841 - f1_score: 0.7039 - val_loss: 0.4055 - val_f1_score: 0.4940
Epoch 43/60
 - 1s - loss: 0.2819 - f1_score: 0.6950 - val_loss: 0.3718 - val_f1_score: 0.5252
Epoch 44/60
 - 1s - loss: 0.2821 - f1_score: 0.6988 - val_loss: 0.3308 - val_f1_score: 0.4636
Epoch 45/60
 - 1s - loss: 0.2764 - f1_score: 0.7053 - val_loss: 0.4263 - val_f1_score: 0.3799
Epoch 46/60
 - 1s - loss: 0.2820 - f1_score: 0.7094 - val_loss: 0.3948 - val_f1_score: 0.5080
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.913755    0.550497     0.813683     0.732126      0.835967
recall        0.842426    0.708200     0.813683     0.775313      0.813683
f1-score      0.876642    0.619469     0.813683     0.748056      0.821571
support    3446.000000  939.000000  4385.000000  4385.000000   4385.000000
auc           0.874085    0.874085     0.913211     0.874363           NaN
******************** DNN ********************
**********  round  1
load and test: shapes for train and test, X/Y
(21102, 314)
(21102, 2)
(4385, 314)
(4385, 2)
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_6 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_3 (Batch (None, 256)               1024      
_________________________________________________________________
activation_3 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
activation_4 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> fn
Train on 16881 samples, validate on 4221 samples
Epoch 1/60
 - 1s - loss: 0.3992 - f1_score: 0.4531 - val_loss: 3.6849 - val_f1_score: 0.3561
Epoch 2/60
 - 1s - loss: 0.3482 - f1_score: 0.6090 - val_loss: 0.4051 - val_f1_score: 0.4927
Epoch 3/60
 - 1s - loss: 0.3467 - f1_score: 0.6025 - val_loss: 0.5694 - val_f1_score: 0.4717
Epoch 4/60
 - 1s - loss: 0.3385 - f1_score: 0.6076 - val_loss: 0.3250 - val_f1_score: 0.4735
Epoch 5/60
 - 1s - loss: 0.3366 - f1_score: 0.6044 - val_loss: 0.4114 - val_f1_score: 0.4931
Epoch 6/60
 - 1s - loss: 0.3345 - f1_score: 0.6352 - val_loss: 0.3249 - val_f1_score: 0.4732
Epoch 7/60
 - 1s - loss: 0.3299 - f1_score: 0.6341 - val_loss: 0.2946 - val_f1_score: 0.4819
Epoch 8/60
 - 1s - loss: 0.3317 - f1_score: 0.6343 - val_loss: 0.3675 - val_f1_score: 0.5129
Epoch 9/60
 - 1s - loss: 0.3278 - f1_score: 0.6361 - val_loss: 0.5269 - val_f1_score: 0.4866
Epoch 10/60
 - 1s - loss: 0.3273 - f1_score: 0.6430 - val_loss: 0.4503 - val_f1_score: 0.4959
Epoch 11/60
 - 1s - loss: 0.3248 - f1_score: 0.6562 - val_loss: 0.3291 - val_f1_score: 0.2117
Epoch 12/60
 - 1s - loss: 0.3241 - f1_score: 0.6398 - val_loss: 0.3130 - val_f1_score: 0.5075
Epoch 13/60
 - 1s - loss: 0.3223 - f1_score: 0.6471 - val_loss: 0.3164 - val_f1_score: 0.4767
Epoch 14/60
 - 1s - loss: 0.3201 - f1_score: 0.6458 - val_loss: 0.3710 - val_f1_score: 0.4802
Epoch 15/60
 - 1s - loss: 0.3210 - f1_score: 0.6564 - val_loss: 0.3330 - val_f1_score: 0.5133
Epoch 16/60
 - 1s - loss: 0.3155 - f1_score: 0.6441 - val_loss: 0.3257 - val_f1_score: 0.4179
Epoch 17/60
 - 1s - loss: 0.3190 - f1_score: 0.6312 - val_loss: 0.3485 - val_f1_score: 0.5224
Epoch 18/60
 - 1s - loss: 0.3157 - f1_score: 0.6518 - val_loss: 0.3416 - val_f1_score: 0.4557
Epoch 19/60
 - 1s - loss: 0.3148 - f1_score: 0.6514 - val_loss: 0.4716 - val_f1_score: 0.2867
Epoch 20/60
 - 1s - loss: 0.3160 - f1_score: 0.6638 - val_loss: 0.3188 - val_f1_score: 0.4792
Epoch 21/60
 - 1s - loss: 0.3151 - f1_score: 0.6537 - val_loss: 0.3304 - val_f1_score: 0.4019
Epoch 22/60
 - 1s - loss: 0.3105 - f1_score: 0.6573 - val_loss: 0.3545 - val_f1_score: 0.2161
Epoch 23/60
 - 1s - loss: 0.3093 - f1_score: 0.6482 - val_loss: 0.3298 - val_f1_score: 0.4183
Epoch 24/60
 - 1s - loss: 0.3075 - f1_score: 0.6621 - val_loss: 0.3919 - val_f1_score: 0.5189
Epoch 25/60
 - 1s - loss: 0.3090 - f1_score: 0.6645 - val_loss: 0.3274 - val_f1_score: 0.4776
Epoch 26/60
 - 1s - loss: 0.3055 - f1_score: 0.6649 - val_loss: 0.3957 - val_f1_score: 0.4967
Epoch 27/60
 - 1s - loss: 0.3010 - f1_score: 0.6713 - val_loss: 0.3263 - val_f1_score: 0.4808
Epoch 28/60
 - 0s - loss: 0.3033 - f1_score: 0.6799 - val_loss: 0.3410 - val_f1_score: 0.5147
Epoch 29/60
 - 1s - loss: 0.3009 - f1_score: 0.6548 - val_loss: 0.3499 - val_f1_score: 0.5190
Epoch 30/60
 - 1s - loss: 0.2985 - f1_score: 0.6849 - val_loss: 0.3684 - val_f1_score: 0.4945
Epoch 31/60
 - 1s - loss: 0.2968 - f1_score: 0.6887 - val_loss: 0.3308 - val_f1_score: 0.4900
Epoch 32/60
 - 1s - loss: 0.2953 - f1_score: 0.6756 - val_loss: 0.3198 - val_f1_score: 0.4663
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.910974    0.566087     0.820525     0.738530      0.837120
recall        0.855194    0.693291     0.820525     0.774243      0.820525
f1-score      0.882203    0.623265     0.820525     0.752734      0.826754
support    3446.000000  939.000000  4385.000000  4385.000000   4385.000000
auc           0.875201    0.875201     0.913061     0.875453           NaN
******************** DNN ********************
**********  round  2
load and test: shapes for train and test, X/Y
(21102, 314)
(21102, 2)
(4385, 314)
(4385, 2)
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_10 (Dense)             (None, 256)               131328    
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024      
_________________________________________________________________
activation_5 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 64)                16448     
_________________________________________________________________
batch_normalization_6 (Batch (None, 64)                256       
_________________________________________________________________
activation_6 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_12:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_13:0' shape=() dtype=int32> fn
Train on 16881 samples, validate on 4221 samples
Epoch 1/60
 - 1s - loss: 0.4233 - f1_score: 0.4375 - val_loss: 1.4988 - val_f1_score: 0.4100
Epoch 2/60
 - 1s - loss: 0.3580 - f1_score: 0.5860 - val_loss: 2.0706 - val_f1_score: 0.3539
Epoch 3/60
 - 1s - loss: 0.3470 - f1_score: 0.5979 - val_loss: 0.7534 - val_f1_score: 0.4408
Epoch 4/60
 - 1s - loss: 0.3385 - f1_score: 0.6199 - val_loss: 0.3779 - val_f1_score: 0.4957
Epoch 5/60
 - 1s - loss: 0.3360 - f1_score: 0.6299 - val_loss: 0.3465 - val_f1_score: 0.5335
Epoch 6/60
 - 1s - loss: 0.3324 - f1_score: 0.6309 - val_loss: 0.5100 - val_f1_score: 0.4811
Epoch 7/60
 - 1s - loss: 0.3343 - f1_score: 0.6391 - val_loss: 0.3714 - val_f1_score: 0.5179
Epoch 8/60
 - 1s - loss: 0.3325 - f1_score: 0.6159 - val_loss: 0.3969 - val_f1_score: 0.5033
Epoch 9/60
 - 1s - loss: 0.3273 - f1_score: 0.6429 - val_loss: 0.3161 - val_f1_score: 0.5128
Epoch 10/60
 - 1s - loss: 0.3267 - f1_score: 0.6315 - val_loss: 0.2878 - val_f1_score: 0.4211
Epoch 11/60
 - 1s - loss: 0.3253 - f1_score: 0.6511 - val_loss: 0.4712 - val_f1_score: 0.4977
Epoch 12/60
 - 1s - loss: 0.3234 - f1_score: 0.6385 - val_loss: 0.3937 - val_f1_score: 0.2343
Epoch 13/60
 - 1s - loss: 0.3254 - f1_score: 0.6444 - val_loss: 0.3091 - val_f1_score: 0.4496
Epoch 14/60
 - 1s - loss: 0.3200 - f1_score: 0.6379 - val_loss: 0.3599 - val_f1_score: 0.5235
Epoch 15/60
 - 1s - loss: 0.3193 - f1_score: 0.6452 - val_loss: 0.3006 - val_f1_score: 0.4455
Epoch 16/60
 - 1s - loss: 0.3217 - f1_score: 0.6509 - val_loss: 0.3145 - val_f1_score: 0.4523
Epoch 17/60
 - 1s - loss: 0.3151 - f1_score: 0.6472 - val_loss: 0.3761 - val_f1_score: 0.3833
Epoch 18/60
 - 1s - loss: 0.3197 - f1_score: 0.6598 - val_loss: 0.3020 - val_f1_score: 0.4309
Epoch 19/60
 - 1s - loss: 0.3153 - f1_score: 0.6484 - val_loss: 0.3436 - val_f1_score: 0.5011
Epoch 20/60
 - 1s - loss: 0.3159 - f1_score: 0.6556 - val_loss: 0.6020 - val_f1_score: 0.4617
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.912830    0.581189     0.827594     0.747009      0.841813
recall        0.863030    0.697551     0.827594     0.780290      0.827594
f1-score      0.887232    0.634076     0.827594     0.760654      0.833021
support    3446.000000  939.000000  4385.000000  4385.000000   4385.000000
auc           0.882226    0.882226     0.918774     0.882472           NaN
