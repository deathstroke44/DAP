Using TensorFlow backend.
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2025-04-16 02:13:19.355224: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2025-04-16 02:13:19.359080: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000000000 Hz
2025-04-16 02:13:19.359344: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e4f835e6f0 executing computations on platform Host. Devices:
2025-04-16 02:13:19.359368: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2025-04-16 02:13:19.428209: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

******************** DNN ********************
**********  round  0
load and test: shapes for train and test, X/Y
(26555, 314)
(26555, 2)
(5345, 314)
(5345, 2)
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_2 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
activation_1 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
activation_2 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn
Train on 21244 samples, validate on 5311 samples
Epoch 1/60
 - 1s - loss: 0.3425 - f1_score: 0.2025 - val_loss: 0.1425 - val_f1_score: 0.0000e+00
Epoch 2/60
 - 1s - loss: 0.2853 - f1_score: 0.3115 - val_loss: 0.0770 - val_f1_score: 0.0000e+00
Epoch 3/60
 - 1s - loss: 0.2807 - f1_score: 0.3197 - val_loss: 0.1080 - val_f1_score: 0.0079
Epoch 4/60
 - 1s - loss: 0.2799 - f1_score: 0.2945 - val_loss: 0.0951 - val_f1_score: 0.0000e+00
Epoch 5/60
 - 1s - loss: 0.2777 - f1_score: 0.3268 - val_loss: 0.0748 - val_f1_score: 0.0000e+00
Epoch 6/60
 - 1s - loss: 0.2735 - f1_score: 0.3263 - val_loss: 0.0799 - val_f1_score: 0.0000e+00
Epoch 7/60
 - 1s - loss: 0.2708 - f1_score: 0.3245 - val_loss: 0.0686 - val_f1_score: 0.0000e+00
Epoch 8/60
 - 1s - loss: 0.2688 - f1_score: 0.3228 - val_loss: 0.1084 - val_f1_score: 0.0049
Epoch 9/60
 - 1s - loss: 0.2680 - f1_score: 0.3648 - val_loss: 0.0722 - val_f1_score: 0.0000e+00
Epoch 10/60
 - 1s - loss: 0.2655 - f1_score: 0.3604 - val_loss: 0.0736 - val_f1_score: 0.0000e+00
Epoch 11/60
 - 1s - loss: 0.2658 - f1_score: 0.3624 - val_loss: 0.0832 - val_f1_score: 0.0000e+00
Epoch 12/60
 - 1s - loss: 0.2649 - f1_score: 0.3886 - val_loss: 0.1052 - val_f1_score: 0.0000e+00
Epoch 13/60
 - 1s - loss: 0.2652 - f1_score: 0.3698 - val_loss: 0.0695 - val_f1_score: 0.0000e+00
Epoch 14/60
 - 1s - loss: 0.2625 - f1_score: 0.3821 - val_loss: 0.0816 - val_f1_score: 0.0000e+00
Epoch 15/60
 - 1s - loss: 0.2611 - f1_score: 0.4046 - val_loss: 0.0634 - val_f1_score: 0.0000e+00
Epoch 16/60
 - 1s - loss: 0.2605 - f1_score: 0.3957 - val_loss: 0.0651 - val_f1_score: 0.0000e+00
Epoch 17/60
 - 1s - loss: 0.2595 - f1_score: 0.4220 - val_loss: 0.1135 - val_f1_score: 0.0000e+00
Epoch 18/60
 - 1s - loss: 0.2571 - f1_score: 0.3973 - val_loss: 0.0630 - val_f1_score: 0.0000e+00
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.920000    0.493617     0.882507     0.706809      0.870382
recall        0.949608    0.372990     0.882507     0.661299      0.882507
f1-score      0.934570    0.424908     0.882507     0.679739      0.875260
support    4723.000000  622.000000  5345.000000  5345.000000   5345.000000
auc           0.844876    0.844876     0.952823     0.845217           NaN
******************** DNN ********************
**********  round  1
load and test: shapes for train and test, X/Y
(26555, 314)
(26555, 2)
(5345, 314)
(5345, 2)
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_6 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_3 (Batch (None, 256)               1024      
_________________________________________________________________
activation_3 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
activation_4 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> fn
Train on 21244 samples, validate on 5311 samples
Epoch 1/60
 - 1s - loss: 0.3534 - f1_score: 0.1983 - val_loss: 0.1112 - val_f1_score: 0.0000e+00
Epoch 2/60
 - 1s - loss: 0.2896 - f1_score: 0.2879 - val_loss: 0.1094 - val_f1_score: 0.0000e+00
Epoch 3/60
 - 1s - loss: 0.2819 - f1_score: 0.2803 - val_loss: 0.0674 - val_f1_score: 0.0000e+00
Epoch 4/60
 - 1s - loss: 0.2774 - f1_score: 0.3434 - val_loss: 0.0722 - val_f1_score: 0.0000e+00
Epoch 5/60
 - 1s - loss: 0.2769 - f1_score: 0.3297 - val_loss: 0.1030 - val_f1_score: 0.0059
Epoch 6/60
 - 1s - loss: 0.2735 - f1_score: 0.2961 - val_loss: 0.0729 - val_f1_score: 0.0000e+00
Epoch 7/60
 - 1s - loss: 0.2729 - f1_score: 0.3440 - val_loss: 0.0726 - val_f1_score: 0.0000e+00
Epoch 8/60
 - 1s - loss: 0.2715 - f1_score: 0.3389 - val_loss: 0.0681 - val_f1_score: 0.0000e+00
Epoch 9/60
 - 1s - loss: 0.2691 - f1_score: 0.3366 - val_loss: 0.0725 - val_f1_score: 0.0000e+00
Epoch 10/60
 - 1s - loss: 0.2696 - f1_score: 0.3154 - val_loss: 0.0740 - val_f1_score: 0.0000e+00
Epoch 11/60
 - 1s - loss: 0.2660 - f1_score: 0.3942 - val_loss: 0.0584 - val_f1_score: 0.0000e+00
Epoch 12/60
 - 1s - loss: 0.2659 - f1_score: 0.3208 - val_loss: 0.0670 - val_f1_score: 0.0000e+00
Epoch 13/60
 - 1s - loss: 0.2657 - f1_score: 0.4168 - val_loss: 0.0863 - val_f1_score: 0.0000e+00
Epoch 14/60
 - 1s - loss: 0.2622 - f1_score: 0.3830 - val_loss: 0.0630 - val_f1_score: 0.0000e+00
Epoch 15/60
 - 1s - loss: 0.2611 - f1_score: 0.3692 - val_loss: 0.0618 - val_f1_score: 0.0000e+00
Epoch 16/60
 - 1s - loss: 0.2593 - f1_score: 0.3537 - val_loss: 0.0750 - val_f1_score: 0.0000e+00
Epoch 17/60
 - 1s - loss: 0.2599 - f1_score: 0.3931 - val_loss: 0.0975 - val_f1_score: 0.0000e+00
Epoch 18/60
 - 1s - loss: 0.2596 - f1_score: 0.3675 - val_loss: 0.1016 - val_f1_score: 0.0304
Epoch 19/60
 - 1s - loss: 0.2588 - f1_score: 0.3953 - val_loss: 0.0806 - val_f1_score: 0.0000e+00
Epoch 20/60
 - 1s - loss: 0.2572 - f1_score: 0.4100 - val_loss: 0.0714 - val_f1_score: 0.0188
Epoch 21/60
 - 1s - loss: 0.2562 - f1_score: 0.3835 - val_loss: 0.0781 - val_f1_score: 0.0000e+00
Epoch 22/60
 - 1s - loss: 0.2558 - f1_score: 0.4150 - val_loss: 0.0914 - val_f1_score: 0.0000e+00
Epoch 23/60
 - 1s - loss: 0.2552 - f1_score: 0.4011 - val_loss: 0.1024 - val_f1_score: 0.0000e+00
Epoch 24/60
 - 1s - loss: 0.2550 - f1_score: 0.3984 - val_loss: 0.1407 - val_f1_score: 0.0000e+00
Epoch 25/60
 - 1s - loss: 0.2529 - f1_score: 0.4235 - val_loss: 0.0821 - val_f1_score: 0.0000e+00
Epoch 26/60
 - 1s - loss: 0.2530 - f1_score: 0.4127 - val_loss: 0.0981 - val_f1_score: 0.0454
Epoch 27/60
 - 1s - loss: 0.2515 - f1_score: 0.3991 - val_loss: 0.0868 - val_f1_score: 0.0000e+00
Epoch 28/60
 - 1s - loss: 0.2503 - f1_score: 0.4187 - val_loss: 0.0969 - val_f1_score: 0.0000e+00
Epoch 29/60
 - 1s - loss: 0.2482 - f1_score: 0.4305 - val_loss: 0.0715 - val_f1_score: 0.0000e+00
Epoch 30/60
 - 1s - loss: 0.2482 - f1_score: 0.4183 - val_loss: 0.0871 - val_f1_score: 0.0000e+00
Epoch 31/60
 - 1s - loss: 0.2475 - f1_score: 0.4395 - val_loss: 0.0982 - val_f1_score: 0.0000e+00
Epoch 32/60
 - 1s - loss: 0.2453 - f1_score: 0.4047 - val_loss: 0.0745 - val_f1_score: 0.0000e+00
Epoch 33/60
 - 1s - loss: 0.2466 - f1_score: 0.4650 - val_loss: 0.0706 - val_f1_score: 0.0000e+00
Epoch 34/60
 - 1s - loss: 0.2456 - f1_score: 0.4592 - val_loss: 0.1189 - val_f1_score: 0.0000e+00
Epoch 35/60
 - 1s - loss: 0.2437 - f1_score: 0.4598 - val_loss: 0.0955 - val_f1_score: 0.0000e+00
Epoch 36/60
 - 1s - loss: 0.2434 - f1_score: 0.4465 - val_loss: 0.0767 - val_f1_score: 0.0000e+00
Epoch 37/60
 - 1s - loss: 0.2425 - f1_score: 0.4560 - val_loss: 0.0734 - val_f1_score: 0.0000e+00
Epoch 38/60
 - 1s - loss: 0.2402 - f1_score: 0.4558 - val_loss: 0.1124 - val_f1_score: 0.0000e+00
Epoch 39/60
 - 1s - loss: 0.2395 - f1_score: 0.4527 - val_loss: 0.1197 - val_f1_score: 0.0000e+00
Epoch 40/60
 - 1s - loss: 0.2367 - f1_score: 0.4739 - val_loss: 0.1072 - val_f1_score: 0.0000e+00
Epoch 41/60
 - 1s - loss: 0.2374 - f1_score: 0.4612 - val_loss: 0.1136 - val_f1_score: 0.0000e+00
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.923806    0.437710     0.869785     0.680758      0.867238
recall        0.929282    0.418006     0.869785     0.673644      0.869785
f1-score      0.926536    0.427632     0.869785     0.677084      0.868478
support    4723.000000  622.000000  5345.000000  5345.000000   5345.000000
auc           0.832459    0.832459     0.944964     0.832786           NaN
******************** DNN ********************
**********  round  2
load and test: shapes for train and test, X/Y
(26555, 314)
(26555, 2)
(5345, 314)
(5345, 2)
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_10 (Dense)             (None, 256)               131328    
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024      
_________________________________________________________________
activation_5 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 64)                16448     
_________________________________________________________________
batch_normalization_6 (Batch (None, 64)                256       
_________________________________________________________________
activation_6 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_12:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_13:0' shape=() dtype=int32> fn
Train on 21244 samples, validate on 5311 samples
Epoch 1/60
 - 1s - loss: 0.3340 - f1_score: 0.2195 - val_loss: 0.1287 - val_f1_score: 0.0000e+00
Epoch 2/60
 - 1s - loss: 0.2856 - f1_score: 0.3237 - val_loss: 0.1118 - val_f1_score: 0.0000e+00
Epoch 3/60
 - 1s - loss: 0.2816 - f1_score: 0.3161 - val_loss: 0.0818 - val_f1_score: 0.0000e+00
Epoch 4/60
 - 1s - loss: 0.2775 - f1_score: 0.3183 - val_loss: 0.1015 - val_f1_score: 0.0049
Epoch 5/60
 - 1s - loss: 0.2774 - f1_score: 0.3248 - val_loss: 0.0891 - val_f1_score: 0.0000e+00
Epoch 6/60
 - 1s - loss: 0.2738 - f1_score: 0.3376 - val_loss: 0.0717 - val_f1_score: 0.0000e+00
Epoch 7/60
 - 1s - loss: 0.2713 - f1_score: 0.3437 - val_loss: 0.0710 - val_f1_score: 0.0000e+00
Epoch 8/60
 - 1s - loss: 0.2710 - f1_score: 0.3476 - val_loss: 0.0933 - val_f1_score: 0.0076
Epoch 9/60
 - 1s - loss: 0.2688 - f1_score: 0.3395 - val_loss: 0.0751 - val_f1_score: 0.0000e+00
Epoch 10/60
 - 1s - loss: 0.2671 - f1_score: 0.3762 - val_loss: 0.0711 - val_f1_score: 0.0000e+00
Epoch 11/60
 - 1s - loss: 0.2653 - f1_score: 0.3586 - val_loss: 0.0819 - val_f1_score: 0.0000e+00
Epoch 12/60
 - 1s - loss: 0.2659 - f1_score: 0.3100 - val_loss: 0.1062 - val_f1_score: 0.0000e+00
Epoch 13/60
 - 1s - loss: 0.2642 - f1_score: 0.3596 - val_loss: 0.0654 - val_f1_score: 0.0000e+00
Epoch 14/60
 - 1s - loss: 0.2613 - f1_score: 0.3458 - val_loss: 0.1079 - val_f1_score: 0.0421
Epoch 15/60
 - 1s - loss: 0.2637 - f1_score: 0.3556 - val_loss: 0.0658 - val_f1_score: 0.0000e+00
Epoch 16/60
 - 1s - loss: 0.2613 - f1_score: 0.3767 - val_loss: 0.0645 - val_f1_score: 0.0000e+00
Epoch 17/60
 - 1s - loss: 0.2577 - f1_score: 0.3825 - val_loss: 0.0676 - val_f1_score: 0.0000e+00
Epoch 18/60
 - 1s - loss: 0.2582 - f1_score: 0.3938 - val_loss: 0.0963 - val_f1_score: 0.0000e+00
Epoch 19/60
 - 1s - loss: 0.2589 - f1_score: 0.3648 - val_loss: 0.0689 - val_f1_score: 0.0000e+00
Epoch 20/60
 - 1s - loss: 0.2566 - f1_score: 0.3991 - val_loss: 0.0876 - val_f1_score: 0.0000e+00
Epoch 21/60
 - 1s - loss: 0.2561 - f1_score: 0.4016 - val_loss: 0.0887 - val_f1_score: 0.0000e+00
Epoch 22/60
 - 1s - loss: 0.2546 - f1_score: 0.4133 - val_loss: 0.0651 - val_f1_score: 0.0000e+00
Epoch 23/60
 - 1s - loss: 0.2541 - f1_score: 0.4140 - val_loss: 0.0742 - val_f1_score: 0.0000e+00
Epoch 24/60
 - 1s - loss: 0.2515 - f1_score: 0.4209 - val_loss: 0.0641 - val_f1_score: 0.0000e+00
Epoch 25/60
 - 1s - loss: 0.2498 - f1_score: 0.3729 - val_loss: 0.0787 - val_f1_score: 0.0183
Epoch 26/60
 - 1s - loss: 0.2529 - f1_score: 0.4324 - val_loss: 0.0737 - val_f1_score: 0.0000e+00
Epoch 27/60
 - 1s - loss: 0.2510 - f1_score: 0.4431 - val_loss: 0.0650 - val_f1_score: 0.0000e+00
Epoch 28/60
 - 1s - loss: 0.2493 - f1_score: 0.3891 - val_loss: 0.0676 - val_f1_score: 0.0000e+00
Epoch 29/60
 - 1s - loss: 0.2489 - f1_score: 0.4239 - val_loss: 0.0703 - val_f1_score: 0.0000e+00
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.945613    0.432155     0.861366     0.688884      0.885862
recall        0.894559    0.609325     0.861366     0.751942      0.861366
f1-score      0.919378    0.505670     0.861366     0.712524      0.871234
support    4723.000000  622.000000  5345.000000  5345.000000   5345.000000
auc           0.875496    0.875496     0.947322     0.875782           NaN
