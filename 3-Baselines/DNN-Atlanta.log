Using TensorFlow backend.
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2025-04-16 02:11:18.615514: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2025-04-16 02:11:18.619420: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000000000 Hz
2025-04-16 02:11:18.620242: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56225ea746f0 executing computations on platform Host. Devices:
2025-04-16 02:11:18.620279: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2025-04-16 02:11:18.689341: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /users/PAS2671/kabir36/.conda/envs/ns_project_2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

******************** DNN ********************
**********  round  0
load and test: shapes for train and test, X/Y
(12085, 314)
(12085, 2)
(2515, 314)
(2515, 2)
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_2 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
activation_1 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
activation_2 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_1:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_2:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_3:0' shape=() dtype=int32> fn
Train on 9668 samples, validate on 2417 samples
Epoch 1/60
 - 1s - loss: 0.3768 - f1_score: 0.4272 - val_loss: 5.1602 - val_f1_score: 0.3346
Epoch 2/60
 - 0s - loss: 0.3030 - f1_score: 0.5733 - val_loss: 1.1165 - val_f1_score: 0.4341
Epoch 3/60
 - 0s - loss: 0.2958 - f1_score: 0.5620 - val_loss: 1.3669 - val_f1_score: 0.4118
Epoch 4/60
 - 0s - loss: 0.2923 - f1_score: 0.5920 - val_loss: 0.5087 - val_f1_score: 0.5712
Epoch 5/60
 - 0s - loss: 0.2885 - f1_score: 0.6375 - val_loss: 0.3986 - val_f1_score: 0.5631
Epoch 6/60
 - 0s - loss: 0.2875 - f1_score: 0.6063 - val_loss: 0.3922 - val_f1_score: 0.5988
Epoch 7/60
 - 0s - loss: 0.2831 - f1_score: 0.5931 - val_loss: 0.3584 - val_f1_score: 0.5257
Epoch 8/60
 - 0s - loss: 0.2850 - f1_score: 0.6184 - val_loss: 0.3335 - val_f1_score: 0.4881
Epoch 9/60
 - 0s - loss: 0.2752 - f1_score: 0.6515 - val_loss: 0.3394 - val_f1_score: 0.2595
Epoch 10/60
 - 0s - loss: 0.2700 - f1_score: 0.6378 - val_loss: 0.3682 - val_f1_score: 0.3803
Epoch 11/60
 - 0s - loss: 0.2693 - f1_score: 0.6688 - val_loss: 0.3550 - val_f1_score: 0.2316
Epoch 12/60
 - 0s - loss: 0.2693 - f1_score: 0.6251 - val_loss: 0.3574 - val_f1_score: 0.3801
Epoch 13/60
 - 0s - loss: 0.2637 - f1_score: 0.6439 - val_loss: 0.4384 - val_f1_score: 0.5604
Epoch 14/60
 - 0s - loss: 0.2650 - f1_score: 0.6263 - val_loss: 0.3707 - val_f1_score: 0.3676
Epoch 15/60
 - 0s - loss: 0.2612 - f1_score: 0.6707 - val_loss: 0.3537 - val_f1_score: 0.3413
Epoch 16/60
 - 0s - loss: 0.2588 - f1_score: 0.6733 - val_loss: 0.4436 - val_f1_score: 0.5426
Epoch 17/60
 - 0s - loss: 0.2571 - f1_score: 0.6703 - val_loss: 0.7731 - val_f1_score: 0.4710
Epoch 18/60
 - 0s - loss: 0.2565 - f1_score: 0.6672 - val_loss: 0.4537 - val_f1_score: 0.5829
Epoch 19/60
 - 0s - loss: 0.2548 - f1_score: 0.6787 - val_loss: 0.4447 - val_f1_score: 0.1693
Epoch 20/60
 - 0s - loss: 0.2531 - f1_score: 0.6770 - val_loss: 0.3660 - val_f1_score: 0.5228
Epoch 21/60
 - 0s - loss: 0.2517 - f1_score: 0.6723 - val_loss: 0.3970 - val_f1_score: 0.5759
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.918455    0.582181     0.831412     0.750318      0.847456
recall        0.862903    0.713748     0.831412     0.788325      0.831412
f1-score      0.889813    0.641286     0.831412     0.765549      0.837341
support    1984.000000  531.000000  2515.000000  2515.000000   2515.000000
auc           0.892353    0.892353     0.917868     0.892774           NaN
******************** DNN ********************
**********  round  1
load and test: shapes for train and test, X/Y
(12085, 314)
(12085, 2)
(2515, 314)
(2515, 2)
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_6 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_3 (Batch (None, 256)               1024      
_________________________________________________________________
activation_3 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 64)                16448     
_________________________________________________________________
batch_normalization_4 (Batch (None, 64)                256       
_________________________________________________________________
activation_4 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> fn
Train on 9668 samples, validate on 2417 samples
Epoch 1/60
 - 1s - loss: 0.3554 - f1_score: 0.4289 - val_loss: 0.7454 - val_f1_score: 0.5229
Epoch 2/60
 - 0s - loss: 0.3002 - f1_score: 0.5837 - val_loss: 0.6007 - val_f1_score: 0.5325
Epoch 3/60
 - 0s - loss: 0.2937 - f1_score: 0.5928 - val_loss: 0.3649 - val_f1_score: 0.4294
Epoch 4/60
 - 0s - loss: 0.2899 - f1_score: 0.5964 - val_loss: 0.3727 - val_f1_score: 0.4592
Epoch 5/60
 - 0s - loss: 0.2859 - f1_score: 0.6189 - val_loss: 0.3812 - val_f1_score: 0.2603
Epoch 6/60
 - 0s - loss: 0.2801 - f1_score: 0.6248 - val_loss: 0.3465 - val_f1_score: 0.4667
Epoch 7/60
 - 0s - loss: 0.2798 - f1_score: 0.6509 - val_loss: 0.4236 - val_f1_score: 0.0884
Epoch 8/60
 - 0s - loss: 0.2733 - f1_score: 0.6306 - val_loss: 0.3822 - val_f1_score: 0.1638
Epoch 9/60
 - 0s - loss: 0.2758 - f1_score: 0.6538 - val_loss: 0.4413 - val_f1_score: 0.1148
Epoch 10/60
 - 0s - loss: 0.2701 - f1_score: 0.6555 - val_loss: 0.3670 - val_f1_score: 0.0694
Epoch 11/60
 - 0s - loss: 0.2702 - f1_score: 0.6489 - val_loss: 0.3595 - val_f1_score: 0.1315
Epoch 12/60
 - 0s - loss: 0.2610 - f1_score: 0.6523 - val_loss: 0.5157 - val_f1_score: 0.0000e+00
Epoch 13/60
 - 0s - loss: 0.2649 - f1_score: 0.6592 - val_loss: 0.3924 - val_f1_score: 0.0167
Epoch 14/60
 - 0s - loss: 0.2637 - f1_score: 0.6705 - val_loss: 0.4161 - val_f1_score: 0.0366
Epoch 15/60
 - 0s - loss: 0.2608 - f1_score: 0.6764 - val_loss: 0.4068 - val_f1_score: 0.1248
Epoch 16/60
 - 0s - loss: 0.2594 - f1_score: 0.6778 - val_loss: 0.3592 - val_f1_score: 0.3737
Epoch 17/60
 - 0s - loss: 0.2564 - f1_score: 0.6529 - val_loss: 0.4014 - val_f1_score: 0.4205
                     0           1    micro avg    macro avg  weighted avg
index                                                                     
precision     0.921296    0.410768     0.717694     0.666032      0.813507
recall        0.702117    0.775895     0.717694     0.739006      0.717694
f1-score      0.796911    0.537158     0.717694     0.667034      0.742068
support    1984.000000  531.000000  2515.000000  2515.000000   2515.000000
auc           0.838412    0.838412     0.812228     0.838888           NaN
******************** DNN ********************
**********  round  2
load and test: shapes for train and test, X/Y
(12085, 314)
(12085, 2)
(2515, 314)
(2515, 2)
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
main_input (InputLayer)      (None, 314)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 512)               161280    
_________________________________________________________________
dense_10 (Dense)             (None, 256)               131328    
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024      
_________________________________________________________________
activation_5 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 64)                16448     
_________________________________________________________________
batch_normalization_6 (Batch (None, 64)                256       
_________________________________________________________________
activation_6 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 2)                 130       
=================================================================
Total params: 310,466
Trainable params: 309,826
Non-trainable params: 640
_________________________________________________________________
None
tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fp
tracking <tf.Variable 'Variable_12:0' shape=() dtype=int32> tp
tracking <tf.Variable 'Variable_13:0' shape=() dtype=int32> fn
Train on 9668 samples, validate on 2417 samples
Epoch 1/60
 - 1s - loss: 0.3867 - f1_score: 0.3979 - val_loss: 1.1146 - val_f1_score: 0.4457
Epoch 2/60
 - 0s - loss: 0.3017 - f1_score: 0.6000 - val_loss: 1.9314 - val_f1_score: 0.4075
Epoch 3/60
 - 0s - loss: 0.2933 - f1_score: 0.5981 - val_loss: 0.9288 - val_f1_score: 0.4959
Epoch 4/60
 - 0s - loss: 0.2890 - f1_score: 0.5699 - val_loss: 0.4480 - val_f1_score: 0.5491
Epoch 5/60
 - 0s - loss: 0.2908 - f1_score: 0.6078 - val_loss: 0.4367 - val_f1_score: 0.3407
Epoch 6/60
 - 0s - loss: 0.2821 - f1_score: 0.6171 - val_loss: 0.5371 - val_f1_score: 0.5423
Epoch 7/60
 - 0s - loss: 0.2800 - f1_score: 0.6318 - val_loss: 0.3680 - val_f1_score: 0.6038
Epoch 8/60
 - 0s - loss: 0.2749 - f1_score: 0.6315 - val_loss: 0.3289 - val_f1_score: 0.3673
Epoch 9/60
 - 0s - loss: 0.2754 - f1_score: 0.6281 - val_loss: 0.3896 - val_f1_score: 0.5993
Epoch 10/60
 - 0s - loss: 0.2708 - f1_score: 0.6443 - val_loss: 0.3710 - val_f1_score: 0.1576
Epoch 11/60
 - 0s - loss: 0.2713 - f1_score: 0.6367 - val_loss: 0.3433 - val_f1_score: 0.5352
Epoch 12/60
 - 0s - loss: 0.2674 - f1_score: 0.6523 - val_loss: 0.3478 - val_f1_score: 0.4551
Epoch 13/60
 - 0s - loss: 0.2688 - f1_score: 0.6451 - val_loss: 0.4032 - val_f1_score: 0.0899
Epoch 14/60
 - 0s - loss: 0.2633 - f1_score: 0.6704 - val_loss: 0.3353 - val_f1_score: 0.3379
Epoch 15/60
 - 0s - loss: 0.2639 - f1_score: 0.6483 - val_loss: 0.4799 - val_f1_score: 0.5555
Epoch 16/60
 - 0s - loss: 0.2602 - f1_score: 0.6399 - val_loss: 0.3506 - val_f1_score: 0.4617
Epoch 17/60
 - 0s - loss: 0.2581 - f1_score: 0.6628 - val_loss: 0.3772 - val_f1_score: 0.5737
Epoch 18/60
 - 0s - loss: 0.2599 - f1_score: 0.6722 - val_loss: 0.4646 - val_f1_score: 0.5135
Epoch 19/60
 - 0s - loss: 0.2548 - f1_score: 0.6797 - val_loss: 0.3964 - val_f1_score: 0.2096
Epoch 20/60
 - 0s - loss: 0.2534 - f1_score: 0.6782 - val_loss: 0.3777 - val_f1_score: 0.2364
Epoch 21/60
 - 0s - loss: 0.2513 - f1_score: 0.6583 - val_loss: 0.4972 - val_f1_score: 0.1687
Epoch 22/60
 - 0s - loss: 0.2499 - f1_score: 0.6610 - val_loss: 0.3908 - val_f1_score: 0.5442
                     0           1   micro avg    macro avg  weighted avg
index                                                                    
precision     0.908763    0.615652     0.84175     0.762208      0.846877
recall        0.888609    0.666667     0.84175     0.777638      0.841750
f1-score      0.898573    0.640145     0.84175     0.769359      0.844010
support    1984.000000  531.000000  2515.00000  2515.000000   2515.000000
auc           0.890515    0.890515     0.92624     0.890958           NaN
